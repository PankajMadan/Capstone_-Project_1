{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Required Python Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Reduced feature Training set\n",
    "X_train_red = pd.read_csv('X_train_final.csv')\n",
    "y_train = pd.read_csv('y_train.final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Reduced feature Test set\n",
    "X_test_red = pd.read_csv('X_test_final.csv')\n",
    "y_test = pd.read_csv('y_test.final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model_16: Stacking Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Loading  the best Voting Classifier model & Neural Network (with Equal Nodes in all the Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Joblib module\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing best Voting Classifier\n",
    "voting_clf = joblib.load('Voting_Red.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Training Set for Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating an empty DataFrame to store training set for Stacking Classifier\n",
    "df_train_stack = pd.DataFrame(columns=['Voting','Neural','True'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the 10 Fold object\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv_strat = StratifiedKFold(10,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting predictions of the Voting & Neural Net classifier for each of 10 folds of Training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Sklearn's roc_auc_score module\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing cross val score from sklearn\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing train test split from Sklearn to produce validation set\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the exponential decay learning rate.\n",
    "def exponential_decay_fn(epoch):\n",
    "            return 0.01 * 0.1**(epoch /4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Neural_Pred(clf, X_tr, y_tr, X_tst):\n",
    "    ''' \n",
    "    This function returns the predictions of Neural Classifier(clf) for the test folds \n",
    "    Parameters:\n",
    "    X_tr : Training set Features\n",
    "    y_tr : Training set Labels\n",
    "    X_tst : Test set Features\n",
    "    '''\n",
    "    # Splitting the Training set further into training & validation set.\n",
    "    X_tr_r, X_val, y_tr_r, y_val = train_test_split(X_tr, y_tr, test_size=0.1, random_state=42, stratify=y_tr)\n",
    "    \n",
    "    # Compiling & Training the Neural Net\n",
    "    clf.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Nadam(beta_1=0.9, beta_2=0.999), metrics=[\"accuracy\"])\n",
    "    \n",
    "    # defining Checkpoints\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint('best_model.h5',save_best_only=True) # 1st Callback\n",
    "    early_stopping_cb = keras.callbacks.EarlyStopping(patience=10)# 2nd Callback\n",
    "    lr_scheduler_cb = keras.callbacks.LearningRateScheduler(exponential_decay_fn)# 3rd Callback\n",
    "    \n",
    "    # Fitting The model\n",
    "    clf.fit(X_tr_r, y_tr_r, epochs=50, validation_data=(X_val,y_val),batch_size=32,\n",
    "    class_weight={0: 1.0, 1: 10.0},callbacks=[checkpoint_cb,early_stopping_cb,lr_scheduler_cb])\n",
    "    \n",
    "    # Loading the best Neural model after training & before making predictions\n",
    "    clf_best = keras.models.load_model('best_model.h5')    \n",
    "    \n",
    "    # Saving the predictions for every fold in a numpy array\n",
    "    return (clf_best.predict_proba(X_tst).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 26689 samples, validate on 2966 samples\n",
      "Epoch 1/50\n",
      "26689/26689 [==============================] - 3s 118us/sample - loss: 1.1968 - accuracy: 0.6985 - val_loss: 1.1504 - val_accuracy: 0.8024\n",
      "Epoch 2/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.1326 - accuracy: 0.7418 - val_loss: 1.0780 - val_accuracy: 0.7953\n",
      "Epoch 3/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.1038 - accuracy: 0.7645 - val_loss: 1.1155 - val_accuracy: 0.7235\n",
      "Epoch 4/50\n",
      "26689/26689 [==============================] - 2s 82us/sample - loss: 1.0890 - accuracy: 0.7792 - val_loss: 1.0952 - val_accuracy: 0.8375\n",
      "Epoch 5/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0760 - accuracy: 0.7840 - val_loss: 1.0524 - val_accuracy: 0.7964\n",
      "Epoch 6/50\n",
      "26689/26689 [==============================] - 2s 78us/sample - loss: 1.0683 - accuracy: 0.7849 - val_loss: 1.0527 - val_accuracy: 0.8149\n",
      "Epoch 7/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0631 - accuracy: 0.7910 - val_loss: 1.0540 - val_accuracy: 0.8176\n",
      "Epoch 8/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.0585 - accuracy: 0.7877 - val_loss: 1.0474 - val_accuracy: 0.8018\n",
      "Epoch 9/50\n",
      "26689/26689 [==============================] - 2s 84us/sample - loss: 1.0563 - accuracy: 0.7887 - val_loss: 1.0517 - val_accuracy: 0.8075\n",
      "Epoch 10/50\n",
      "26689/26689 [==============================] - 2s 85us/sample - loss: 1.0545 - accuracy: 0.7918 - val_loss: 1.0507 - val_accuracy: 0.7991\n",
      "Epoch 11/50\n",
      "26689/26689 [==============================] - 2s 75us/sample - loss: 1.0532 - accuracy: 0.7885 - val_loss: 1.0510 - val_accuracy: 0.7977\n",
      "Epoch 12/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0526 - accuracy: 0.7858 - val_loss: 1.0515 - val_accuracy: 0.8004\n",
      "Epoch 13/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0523 - accuracy: 0.7900 - val_loss: 1.0515 - val_accuracy: 0.7997\n",
      "Epoch 14/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0520 - accuracy: 0.7892 - val_loss: 1.0515 - val_accuracy: 0.8004\n",
      "Epoch 15/50\n",
      "26689/26689 [==============================] - 2s 72us/sample - loss: 1.0519 - accuracy: 0.7893 - val_loss: 1.0515 - val_accuracy: 0.8004\n",
      "Epoch 16/50\n",
      "26689/26689 [==============================] - 2s 72us/sample - loss: 1.0518 - accuracy: 0.7901 - val_loss: 1.0515 - val_accuracy: 0.8004\n",
      "Epoch 17/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.0518 - accuracy: 0.7898 - val_loss: 1.0515 - val_accuracy: 0.8004\n",
      "Epoch 18/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.0518 - accuracy: 0.7896 - val_loss: 1.0515 - val_accuracy: 0.8004\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 26689 samples, validate on 2966 samples\n",
      "Epoch 1/50\n",
      "26689/26689 [==============================] - 3s 102us/sample - loss: 1.1895 - accuracy: 0.7031 - val_loss: 1.2075 - val_accuracy: 0.8560\n",
      "Epoch 2/50\n",
      "26689/26689 [==============================] - 2s 71us/sample - loss: 1.1275 - accuracy: 0.7382 - val_loss: 1.1049 - val_accuracy: 0.7748\n",
      "Epoch 3/50\n",
      "26689/26689 [==============================] - 2s 71us/sample - loss: 1.0983 - accuracy: 0.7645 - val_loss: 1.0889 - val_accuracy: 0.7950\n",
      "Epoch 4/50\n",
      "26689/26689 [==============================] - 2s 71us/sample - loss: 1.0799 - accuracy: 0.7767 - val_loss: 1.0883 - val_accuracy: 0.8146\n",
      "Epoch 5/50\n",
      "26689/26689 [==============================] - 2s 74us/sample - loss: 1.0683 - accuracy: 0.7804 - val_loss: 1.0796 - val_accuracy: 0.7549\n",
      "Epoch 6/50\n",
      "26689/26689 [==============================] - 2s 70us/sample - loss: 1.0588 - accuracy: 0.7814 - val_loss: 1.0908 - val_accuracy: 0.8200\n",
      "Epoch 7/50\n",
      "26689/26689 [==============================] - 2s 69us/sample - loss: 1.0525 - accuracy: 0.7881 - val_loss: 1.0818 - val_accuracy: 0.7808\n",
      "Epoch 8/50\n",
      "26689/26689 [==============================] - 2s 69us/sample - loss: 1.0480 - accuracy: 0.7882 - val_loss: 1.0809 - val_accuracy: 0.7987\n",
      "Epoch 9/50\n",
      "26689/26689 [==============================] - 2s 69us/sample - loss: 1.0452 - accuracy: 0.7896 - val_loss: 1.0816 - val_accuracy: 0.8051\n",
      "Epoch 10/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.0430 - accuracy: 0.7911 - val_loss: 1.0791 - val_accuracy: 0.7974\n",
      "Epoch 11/50\n",
      "26689/26689 [==============================] - 2s 70us/sample - loss: 1.0417 - accuracy: 0.7907 - val_loss: 1.0795 - val_accuracy: 0.7984\n",
      "Epoch 12/50\n",
      "26689/26689 [==============================] - 2s 69us/sample - loss: 1.0409 - accuracy: 0.7907 - val_loss: 1.0792 - val_accuracy: 0.7967\n",
      "Epoch 13/50\n",
      "26689/26689 [==============================] - 2s 69us/sample - loss: 1.0406 - accuracy: 0.7890 - val_loss: 1.0796 - val_accuracy: 0.7987\n",
      "Epoch 14/50\n",
      "26689/26689 [==============================] - 2s 70us/sample - loss: 1.0403 - accuracy: 0.7896 - val_loss: 1.0797 - val_accuracy: 0.7991\n",
      "Epoch 15/50\n",
      "26689/26689 [==============================] - 2s 70us/sample - loss: 1.0402 - accuracy: 0.7899 - val_loss: 1.0798 - val_accuracy: 0.7991\n",
      "Epoch 16/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0401 - accuracy: 0.7904 - val_loss: 1.0798 - val_accuracy: 0.7991\n",
      "Epoch 17/50\n",
      "26689/26689 [==============================] - 2s 70us/sample - loss: 1.0401 - accuracy: 0.7904 - val_loss: 1.0798 - val_accuracy: 0.7991\n",
      "Epoch 18/50\n",
      "26689/26689 [==============================] - 2s 70us/sample - loss: 1.0401 - accuracy: 0.7903 - val_loss: 1.0798 - val_accuracy: 0.7991\n",
      "Epoch 19/50\n",
      "26689/26689 [==============================] - 2s 70us/sample - loss: 1.0400 - accuracy: 0.7904 - val_loss: 1.0798 - val_accuracy: 0.7991\n",
      "Epoch 20/50\n",
      "26689/26689 [==============================] - 2s 75us/sample - loss: 1.0400 - accuracy: 0.7904 - val_loss: 1.0798 - val_accuracy: 0.7991\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 26689 samples, validate on 2966 samples\n",
      "Epoch 1/50\n",
      "26689/26689 [==============================] - 3s 110us/sample - loss: 1.1883 - accuracy: 0.6967 - val_loss: 1.6387 - val_accuracy: 0.8904\n",
      "Epoch 2/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.1293 - accuracy: 0.7308 - val_loss: 1.3698 - val_accuracy: 0.8550\n",
      "Epoch 3/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.1015 - accuracy: 0.7576 - val_loss: 1.1875 - val_accuracy: 0.8078\n",
      "Epoch 4/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0835 - accuracy: 0.7669 - val_loss: 1.0878 - val_accuracy: 0.8274\n",
      "Epoch 5/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0713 - accuracy: 0.7753 - val_loss: 1.1178 - val_accuracy: 0.8378\n",
      "Epoch 6/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0651 - accuracy: 0.7850 - val_loss: 1.0955 - val_accuracy: 0.8250\n",
      "Epoch 7/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0573 - accuracy: 0.7858 - val_loss: 1.0878 - val_accuracy: 0.7960\n",
      "Epoch 8/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0536 - accuracy: 0.7803 - val_loss: 1.0964 - val_accuracy: 0.8179\n",
      "Epoch 9/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0506 - accuracy: 0.7873 - val_loss: 1.0868 - val_accuracy: 0.7940\n",
      "Epoch 10/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0487 - accuracy: 0.7817 - val_loss: 1.0869 - val_accuracy: 0.7977\n",
      "Epoch 11/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0474 - accuracy: 0.7878 - val_loss: 1.0869 - val_accuracy: 0.7933\n",
      "Epoch 12/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0467 - accuracy: 0.7805 - val_loss: 1.0880 - val_accuracy: 0.7977\n",
      "Epoch 13/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0464 - accuracy: 0.7873 - val_loss: 1.0875 - val_accuracy: 0.7940\n",
      "Epoch 14/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0461 - accuracy: 0.7847 - val_loss: 1.0875 - val_accuracy: 0.7940\n",
      "Epoch 15/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0460 - accuracy: 0.7846 - val_loss: 1.0875 - val_accuracy: 0.7940\n",
      "Epoch 16/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0459 - accuracy: 0.7842 - val_loss: 1.0875 - val_accuracy: 0.7940\n",
      "Epoch 17/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0459 - accuracy: 0.7843 - val_loss: 1.0875 - val_accuracy: 0.7940\n",
      "Epoch 18/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0458 - accuracy: 0.7843 - val_loss: 1.0875 - val_accuracy: 0.7940\n",
      "Epoch 19/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0458 - accuracy: 0.7842 - val_loss: 1.0875 - val_accuracy: 0.7940\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 26689 samples, validate on 2966 samples\n",
      "Epoch 1/50\n",
      "26689/26689 [==============================] - 3s 108us/sample - loss: 1.1807 - accuracy: 0.6997 - val_loss: 1.2662 - val_accuracy: 0.8240\n",
      "Epoch 2/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.1211 - accuracy: 0.7429 - val_loss: 1.1817 - val_accuracy: 0.8328\n",
      "Epoch 3/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0893 - accuracy: 0.7664 - val_loss: 1.1276 - val_accuracy: 0.8223\n",
      "Epoch 4/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0713 - accuracy: 0.7789 - val_loss: 1.0995 - val_accuracy: 0.8146\n",
      "Epoch 5/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0588 - accuracy: 0.7881 - val_loss: 1.0824 - val_accuracy: 0.8115\n",
      "Epoch 6/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0487 - accuracy: 0.7927 - val_loss: 1.0854 - val_accuracy: 0.8267\n",
      "Epoch 7/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0428 - accuracy: 0.8016 - val_loss: 1.0819 - val_accuracy: 0.8001\n",
      "Epoch 8/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0372 - accuracy: 0.7971 - val_loss: 1.0826 - val_accuracy: 0.7866\n",
      "Epoch 9/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0337 - accuracy: 0.7928 - val_loss: 1.0853 - val_accuracy: 0.8088\n",
      "Epoch 10/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0318 - accuracy: 0.7964 - val_loss: 1.0856 - val_accuracy: 0.8122\n",
      "Epoch 11/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0304 - accuracy: 0.8003 - val_loss: 1.0840 - val_accuracy: 0.8071\n",
      "Epoch 12/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0297 - accuracy: 0.7984 - val_loss: 1.0839 - val_accuracy: 0.8078\n",
      "Epoch 13/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0292 - accuracy: 0.7983 - val_loss: 1.0843 - val_accuracy: 0.8082\n",
      "Epoch 14/50\n",
      "26689/26689 [==============================] - 2s 75us/sample - loss: 1.0290 - accuracy: 0.7991 - val_loss: 1.0843 - val_accuracy: 0.8075\n",
      "Epoch 15/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0288 - accuracy: 0.7987 - val_loss: 1.0842 - val_accuracy: 0.8078\n",
      "Epoch 16/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0287 - accuracy: 0.7982 - val_loss: 1.0842 - val_accuracy: 0.8071\n",
      "Epoch 17/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0287 - accuracy: 0.7984 - val_loss: 1.0842 - val_accuracy: 0.8071\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 26689 samples, validate on 2966 samples\n",
      "Epoch 1/50\n",
      "26689/26689 [==============================] - 3s 105us/sample - loss: 1.1860 - accuracy: 0.7078 - val_loss: 1.2889 - val_accuracy: 0.7374\n",
      "Epoch 2/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.1247 - accuracy: 0.7377 - val_loss: 1.1205 - val_accuracy: 0.8345\n",
      "Epoch 3/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.0919 - accuracy: 0.7616 - val_loss: 1.1392 - val_accuracy: 0.8567\n",
      "Epoch 4/50\n",
      "26689/26689 [==============================] - 2s 72us/sample - loss: 1.0741 - accuracy: 0.7742 - val_loss: 1.1368 - val_accuracy: 0.8432\n",
      "Epoch 5/50\n",
      "26689/26689 [==============================] - 2s 72us/sample - loss: 1.0627 - accuracy: 0.7871 - val_loss: 1.1015 - val_accuracy: 0.8102\n",
      "Epoch 6/50\n",
      "26689/26689 [==============================] - 2s 72us/sample - loss: 1.0537 - accuracy: 0.7903 - val_loss: 1.0929 - val_accuracy: 0.8038\n",
      "Epoch 7/50\n",
      "26689/26689 [==============================] - 2s 72us/sample - loss: 1.0479 - accuracy: 0.7832 - val_loss: 1.0896 - val_accuracy: 0.8139\n",
      "Epoch 8/50\n",
      "26689/26689 [==============================] - 2s 72us/sample - loss: 1.0435 - accuracy: 0.7904 - val_loss: 1.0878 - val_accuracy: 0.8058\n",
      "Epoch 9/50\n",
      "26689/26689 [==============================] - 2s 72us/sample - loss: 1.0402 - accuracy: 0.7920 - val_loss: 1.0854 - val_accuracy: 0.7933\n",
      "Epoch 10/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.0390 - accuracy: 0.7906 - val_loss: 1.0860 - val_accuracy: 0.7994\n",
      "Epoch 11/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.0379 - accuracy: 0.7895 - val_loss: 1.0863 - val_accuracy: 0.8018\n",
      "Epoch 12/50\n",
      "26689/26689 [==============================] - 2s 71us/sample - loss: 1.0372 - accuracy: 0.7964 - val_loss: 1.0857 - val_accuracy: 0.7994\n",
      "Epoch 13/50\n",
      "26689/26689 [==============================] - 2s 72us/sample - loss: 1.0368 - accuracy: 0.7904 - val_loss: 1.0860 - val_accuracy: 0.8004\n",
      "Epoch 14/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.0366 - accuracy: 0.7934 - val_loss: 1.0859 - val_accuracy: 0.7997\n",
      "Epoch 15/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.0364 - accuracy: 0.7935 - val_loss: 1.0859 - val_accuracy: 0.8001\n",
      "Epoch 16/50\n",
      "26689/26689 [==============================] - 2s 71us/sample - loss: 1.0364 - accuracy: 0.7931 - val_loss: 1.0858 - val_accuracy: 0.8001\n",
      "Epoch 17/50\n",
      "26689/26689 [==============================] - 2s 71us/sample - loss: 1.0363 - accuracy: 0.7930 - val_loss: 1.0858 - val_accuracy: 0.8001\n",
      "Epoch 18/50\n",
      "26689/26689 [==============================] - 2s 72us/sample - loss: 1.0363 - accuracy: 0.7927 - val_loss: 1.0858 - val_accuracy: 0.8001\n",
      "Epoch 19/50\n",
      "26689/26689 [==============================] - 2s 72us/sample - loss: 1.0363 - accuracy: 0.7929 - val_loss: 1.0858 - val_accuracy: 0.8001\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 26689 samples, validate on 2966 samples\n",
      "Epoch 1/50\n",
      "26689/26689 [==============================] - 3s 110us/sample - loss: 1.1830 - accuracy: 0.7088 - val_loss: 1.2224 - val_accuracy: 0.8510\n",
      "Epoch 2/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.1221 - accuracy: 0.7433 - val_loss: 1.1953 - val_accuracy: 0.4747\n",
      "Epoch 3/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0957 - accuracy: 0.7707 - val_loss: 1.1239 - val_accuracy: 0.8071\n",
      "Epoch 4/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0772 - accuracy: 0.7829 - val_loss: 1.1187 - val_accuracy: 0.6180\n",
      "Epoch 5/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0670 - accuracy: 0.7755 - val_loss: 1.0852 - val_accuracy: 0.8183\n",
      "Epoch 6/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0594 - accuracy: 0.7943 - val_loss: 1.0843 - val_accuracy: 0.7987\n",
      "Epoch 7/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0534 - accuracy: 0.7905 - val_loss: 1.0848 - val_accuracy: 0.8038\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0498 - accuracy: 0.7968 - val_loss: 1.0811 - val_accuracy: 0.7903\n",
      "Epoch 9/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0473 - accuracy: 0.7910 - val_loss: 1.0815 - val_accuracy: 0.8021\n",
      "Epoch 10/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0455 - accuracy: 0.7958 - val_loss: 1.0815 - val_accuracy: 0.8028\n",
      "Epoch 11/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0445 - accuracy: 0.7938 - val_loss: 1.0809 - val_accuracy: 0.7994\n",
      "Epoch 12/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0439 - accuracy: 0.7922 - val_loss: 1.0812 - val_accuracy: 0.8018\n",
      "Epoch 13/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0436 - accuracy: 0.7954 - val_loss: 1.0812 - val_accuracy: 0.8021\n",
      "Epoch 14/50\n",
      "26689/26689 [==============================] - 2s 85us/sample - loss: 1.0434 - accuracy: 0.7970 - val_loss: 1.0813 - val_accuracy: 0.8028\n",
      "Epoch 15/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0433 - accuracy: 0.7971 - val_loss: 1.0812 - val_accuracy: 0.8024\n",
      "Epoch 16/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0432 - accuracy: 0.7967 - val_loss: 1.0812 - val_accuracy: 0.8024\n",
      "Epoch 17/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0432 - accuracy: 0.7967 - val_loss: 1.0812 - val_accuracy: 0.8024\n",
      "Epoch 18/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0431 - accuracy: 0.7967 - val_loss: 1.0812 - val_accuracy: 0.8024\n",
      "Epoch 19/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0431 - accuracy: 0.7965 - val_loss: 1.0812 - val_accuracy: 0.8024\n",
      "Epoch 20/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0431 - accuracy: 0.7966 - val_loss: 1.0812 - val_accuracy: 0.8024\n",
      "Epoch 21/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0431 - accuracy: 0.7966 - val_loss: 1.0812 - val_accuracy: 0.8024\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 26689 samples, validate on 2966 samples\n",
      "Epoch 1/50\n",
      "26689/26689 [==============================] - 3s 106us/sample - loss: 1.1861 - accuracy: 0.7012 - val_loss: 3.0164 - val_accuracy: 0.2876\n",
      "Epoch 2/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.1401 - accuracy: 0.7311 - val_loss: 1.2191 - val_accuracy: 0.4987\n",
      "Epoch 3/50\n",
      "26689/26689 [==============================] - 2s 72us/sample - loss: 1.0913 - accuracy: 0.7598 - val_loss: 1.2683 - val_accuracy: 0.8719\n",
      "Epoch 4/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.0714 - accuracy: 0.7734 - val_loss: 1.0943 - val_accuracy: 0.7067\n",
      "Epoch 5/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.0628 - accuracy: 0.7865 - val_loss: 1.0874 - val_accuracy: 0.8264\n",
      "Epoch 6/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.0502 - accuracy: 0.7849 - val_loss: 1.0840 - val_accuracy: 0.8146\n",
      "Epoch 7/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.0407 - accuracy: 0.7929 - val_loss: 1.0791 - val_accuracy: 0.7896\n",
      "Epoch 8/50\n",
      "26689/26689 [==============================] - 2s 72us/sample - loss: 1.0350 - accuracy: 0.7912 - val_loss: 1.0800 - val_accuracy: 0.7910\n",
      "Epoch 9/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.0313 - accuracy: 0.7889 - val_loss: 1.0877 - val_accuracy: 0.8142\n",
      "Epoch 10/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.0289 - accuracy: 0.7938 - val_loss: 1.0828 - val_accuracy: 0.8004\n",
      "Epoch 11/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.0272 - accuracy: 0.7920 - val_loss: 1.0836 - val_accuracy: 0.8011\n",
      "Epoch 12/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.0262 - accuracy: 0.7963 - val_loss: 1.0815 - val_accuracy: 0.7913\n",
      "Epoch 13/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.0260 - accuracy: 0.7881 - val_loss: 1.0830 - val_accuracy: 0.7977\n",
      "Epoch 14/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.0256 - accuracy: 0.7925 - val_loss: 1.0830 - val_accuracy: 0.7970\n",
      "Epoch 15/50\n",
      "26689/26689 [==============================] - 2s 72us/sample - loss: 1.0254 - accuracy: 0.7907 - val_loss: 1.0831 - val_accuracy: 0.7974\n",
      "Epoch 16/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.0253 - accuracy: 0.7932 - val_loss: 1.0831 - val_accuracy: 0.7974\n",
      "Epoch 17/50\n",
      "26689/26689 [==============================] - 2s 72us/sample - loss: 1.0253 - accuracy: 0.7918 - val_loss: 1.0831 - val_accuracy: 0.7977\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 26689 samples, validate on 2966 samples\n",
      "Epoch 1/50\n",
      "26689/26689 [==============================] - 3s 104us/sample - loss: 1.1875 - accuracy: 0.7072 - val_loss: 1.5344 - val_accuracy: 0.8628\n",
      "Epoch 2/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.1237 - accuracy: 0.7352 - val_loss: 1.2523 - val_accuracy: 0.8564\n",
      "Epoch 3/50\n",
      "26689/26689 [==============================] - 2s 74us/sample - loss: 1.0988 - accuracy: 0.7672 - val_loss: 1.1271 - val_accuracy: 0.8375\n",
      "Epoch 4/50\n",
      "26689/26689 [==============================] - 2s 74us/sample - loss: 1.0823 - accuracy: 0.7822 - val_loss: 1.1116 - val_accuracy: 0.8223\n",
      "Epoch 5/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.0675 - accuracy: 0.7927 - val_loss: 1.0905 - val_accuracy: 0.8294\n",
      "Epoch 6/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.0612 - accuracy: 0.7969 - val_loss: 1.0728 - val_accuracy: 0.7916\n",
      "Epoch 7/50\n",
      "26689/26689 [==============================] - 2s 74us/sample - loss: 1.0549 - accuracy: 0.7957 - val_loss: 1.0727 - val_accuracy: 0.8028\n",
      "Epoch 8/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.0510 - accuracy: 0.7976 - val_loss: 1.0746 - val_accuracy: 0.8125\n",
      "Epoch 9/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.0480 - accuracy: 0.7961 - val_loss: 1.0737 - val_accuracy: 0.8095\n",
      "Epoch 10/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.0464 - accuracy: 0.7976 - val_loss: 1.0737 - val_accuracy: 0.8098\n",
      "Epoch 11/50\n",
      "26689/26689 [==============================] - 2s 74us/sample - loss: 1.0453 - accuracy: 0.7996 - val_loss: 1.0739 - val_accuracy: 0.8122\n",
      "Epoch 12/50\n",
      "26689/26689 [==============================] - 2s 74us/sample - loss: 1.0447 - accuracy: 0.7985 - val_loss: 1.0736 - val_accuracy: 0.8122\n",
      "Epoch 13/50\n",
      "26689/26689 [==============================] - 2s 73us/sample - loss: 1.0443 - accuracy: 0.7997 - val_loss: 1.0735 - val_accuracy: 0.8129\n",
      "Epoch 14/50\n",
      "26689/26689 [==============================] - 2s 74us/sample - loss: 1.0440 - accuracy: 0.7993 - val_loss: 1.0736 - val_accuracy: 0.8132\n",
      "Epoch 15/50\n",
      "26689/26689 [==============================] - 2s 74us/sample - loss: 1.0439 - accuracy: 0.7997 - val_loss: 1.0735 - val_accuracy: 0.8132\n",
      "Epoch 16/50\n",
      "26689/26689 [==============================] - 2s 74us/sample - loss: 1.0438 - accuracy: 0.7993 - val_loss: 1.0735 - val_accuracy: 0.8132\n",
      "Epoch 17/50\n",
      "26689/26689 [==============================] - 2s 74us/sample - loss: 1.0438 - accuracy: 0.7993 - val_loss: 1.0735 - val_accuracy: 0.8132\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 26689 samples, validate on 2966 samples\n",
      "Epoch 1/50\n",
      "26689/26689 [==============================] - 3s 103us/sample - loss: 1.1822 - accuracy: 0.7075 - val_loss: 1.2072 - val_accuracy: 0.7566\n",
      "Epoch 2/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.1232 - accuracy: 0.7430 - val_loss: 1.1413 - val_accuracy: 0.8200\n",
      "Epoch 3/50\n",
      "26689/26689 [==============================] - 2s 75us/sample - loss: 1.0949 - accuracy: 0.7690 - val_loss: 1.0997 - val_accuracy: 0.7127\n",
      "Epoch 4/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0787 - accuracy: 0.7858 - val_loss: 1.0788 - val_accuracy: 0.8061\n",
      "Epoch 5/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0705 - accuracy: 0.8009 - val_loss: 1.0713 - val_accuracy: 0.7980\n",
      "Epoch 6/50\n",
      "26689/26689 [==============================] - 2s 75us/sample - loss: 1.0623 - accuracy: 0.7984 - val_loss: 1.0702 - val_accuracy: 0.7964\n",
      "Epoch 7/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0579 - accuracy: 0.8014 - val_loss: 1.0741 - val_accuracy: 0.8281\n",
      "Epoch 8/50\n",
      "26689/26689 [==============================] - 2s 75us/sample - loss: 1.0548 - accuracy: 0.8035 - val_loss: 1.0707 - val_accuracy: 0.8264\n",
      "Epoch 9/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0520 - accuracy: 0.8058 - val_loss: 1.0665 - val_accuracy: 0.8146\n",
      "Epoch 10/50\n",
      "26689/26689 [==============================] - 2s 75us/sample - loss: 1.0502 - accuracy: 0.8005 - val_loss: 1.0666 - val_accuracy: 0.8189\n",
      "Epoch 11/50\n",
      "26689/26689 [==============================] - ETA: 0s - loss: 1.0482 - accuracy: 0.80 - 2s 76us/sample - loss: 1.0493 - accuracy: 0.8031 - val_loss: 1.0668 - val_accuracy: 0.8203\n",
      "Epoch 12/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0488 - accuracy: 0.8048 - val_loss: 1.0663 - val_accuracy: 0.8176\n",
      "Epoch 13/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0485 - accuracy: 0.8042 - val_loss: 1.0661 - val_accuracy: 0.8173\n",
      "Epoch 14/50\n",
      "26689/26689 [==============================] - 2s 77us/sample - loss: 1.0483 - accuracy: 0.8033 - val_loss: 1.0661 - val_accuracy: 0.8173\n",
      "Epoch 15/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0482 - accuracy: 0.8028 - val_loss: 1.0661 - val_accuracy: 0.8169\n",
      "Epoch 16/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0481 - accuracy: 0.8028 - val_loss: 1.0661 - val_accuracy: 0.8169\n",
      "Epoch 17/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0481 - accuracy: 0.8031 - val_loss: 1.0661 - val_accuracy: 0.8169\n",
      "Epoch 18/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0481 - accuracy: 0.8030 - val_loss: 1.0661 - val_accuracy: 0.8169\n",
      "Epoch 19/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0480 - accuracy: 0.8028 - val_loss: 1.0661 - val_accuracy: 0.8169\n",
      "Epoch 20/50\n",
      "26689/26689 [==============================] - 2s 75us/sample - loss: 1.0480 - accuracy: 0.8028 - val_loss: 1.0661 - val_accuracy: 0.8169\n",
      "Epoch 21/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0480 - accuracy: 0.8028 - val_loss: 1.0661 - val_accuracy: 0.8169\n",
      "Epoch 22/50\n",
      "26689/26689 [==============================] - 2s 75us/sample - loss: 1.0480 - accuracy: 0.8028 - val_loss: 1.0661 - val_accuracy: 0.8169\n",
      "Epoch 23/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0480 - accuracy: 0.8028 - val_loss: 1.0661 - val_accuracy: 0.8169\n",
      "Epoch 24/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0480 - accuracy: 0.8028 - val_loss: 1.0661 - val_accuracy: 0.8169\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 26689 samples, validate on 2966 samples\n",
      "Epoch 1/50\n",
      "26689/26689 [==============================] - 3s 103us/sample - loss: 1.1797 - accuracy: 0.7046 - val_loss: 1.2568 - val_accuracy: 0.7906\n",
      "Epoch 2/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.1293 - accuracy: 0.7393 - val_loss: 1.1650 - val_accuracy: 0.8506\n",
      "Epoch 3/50\n",
      "26689/26689 [==============================] - 2s 75us/sample - loss: 1.0932 - accuracy: 0.7727 - val_loss: 1.3095 - val_accuracy: 0.8129\n",
      "Epoch 4/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0751 - accuracy: 0.7823 - val_loss: 1.1004 - val_accuracy: 0.7883\n",
      "Epoch 5/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0619 - accuracy: 0.7890 - val_loss: 1.1488 - val_accuracy: 0.6827\n",
      "Epoch 6/50\n",
      "26689/26689 [==============================] - 2s 75us/sample - loss: 1.0587 - accuracy: 0.7862 - val_loss: 1.1069 - val_accuracy: 0.8102\n",
      "Epoch 7/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0470 - accuracy: 0.7934 - val_loss: 1.0926 - val_accuracy: 0.7916\n",
      "Epoch 8/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0431 - accuracy: 0.7982 - val_loss: 1.0925 - val_accuracy: 0.7943\n",
      "Epoch 9/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0403 - accuracy: 0.7991 - val_loss: 1.0951 - val_accuracy: 0.8102\n",
      "Epoch 10/50\n",
      "26689/26689 [==============================] - 2s 75us/sample - loss: 1.0383 - accuracy: 0.7974 - val_loss: 1.0965 - val_accuracy: 0.8173\n",
      "Epoch 11/50\n",
      "26689/26689 [==============================] - 2s 87us/sample - loss: 1.0373 - accuracy: 0.8041 - val_loss: 1.0937 - val_accuracy: 0.8082\n",
      "Epoch 12/50\n",
      "26689/26689 [==============================] - 2s 85us/sample - loss: 1.0364 - accuracy: 0.8003 - val_loss: 1.0936 - val_accuracy: 0.8078\n",
      "Epoch 13/50\n",
      "26689/26689 [==============================] - 2s 86us/sample - loss: 1.0360 - accuracy: 0.7980 - val_loss: 1.0938 - val_accuracy: 0.8088\n",
      "Epoch 14/50\n",
      "26689/26689 [==============================] - 2s 85us/sample - loss: 1.0358 - accuracy: 0.7993 - val_loss: 1.0938 - val_accuracy: 0.8098\n",
      "Epoch 15/50\n",
      "26689/26689 [==============================] - 2s 86us/sample - loss: 1.0357 - accuracy: 0.7977 - val_loss: 1.0939 - val_accuracy: 0.8105\n",
      "Epoch 16/50\n",
      "26689/26689 [==============================] - ETA: 0s - loss: 1.0361 - accuracy: 0.79 - 2s 80us/sample - loss: 1.0356 - accuracy: 0.7988 - val_loss: 1.0939 - val_accuracy: 0.8105\n",
      "Epoch 17/50\n",
      "26689/26689 [==============================] - 2s 78us/sample - loss: 1.0356 - accuracy: 0.7986 - val_loss: 1.0939 - val_accuracy: 0.8105\n",
      "Epoch 18/50\n",
      "26689/26689 [==============================] - 2s 76us/sample - loss: 1.0355 - accuracy: 0.7988 - val_loss: 1.0939 - val_accuracy: 0.8105\n"
     ]
    }
   ],
   "source": [
    "# Computing Voting Classifier's & Neural Net 10 fold conditional prob predictions on the training set for Stacking classifier\n",
    "for train_index, test_index in cv_strat.split(X_train_red, y_train):\n",
    "    # Creating  Folds\n",
    "    X_tr, X_tst = X_train_red.loc[train_index], X_train_red.loc[test_index]\n",
    "    y_tr, y_tst = y_train.loc[train_index], y_train.loc[test_index]\n",
    "    \n",
    "    # Fitting the best Voting Classifier on the Training Folds\n",
    "    voting_clf.fit(X_tr, y_tr)\n",
    "    # Making Predictions on the testing Fold.\n",
    "    y_pred_voting = voting_clf.predict_proba(X_tst)[:,1]\n",
    "    \n",
    "    \n",
    "    # Loading the fresh best Neural net classifier\n",
    "    neural = keras.models.load_model('Best_model_Selu_eq_Learn.h5')\n",
    "    # Fitting the best Neural Net on Training Folds & obtaining  predictions\n",
    "    y_pred_neural = Neural_Pred(neural, X_tr, y_tr, X_tst)\n",
    "    \n",
    "    # Storing the predictions in a dataframe\n",
    "    df_temp = pd.DataFrame(columns=['Voting','Neural','True'])\n",
    "    df_temp['Voting'] = y_pred_voting\n",
    "    df_temp['Neural'] = y_pred_neural\n",
    "    df_temp['True'] = y_tst.values.flatten() # As y_tst is a dataframe we first convert it into a 2d numpy vector\n",
    "    # array, which is is then converted to 1d array using .flatten()\n",
    "    \n",
    "    # Appending the df_temp to df_train_stack\n",
    "    df_train_stack = df_train_stack.append(df_temp,ignore_index=True)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32950 entries, 0 to 32949\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Voting  32950 non-null  float64\n",
      " 1   Neural  32950 non-null  float32\n",
      " 2   True    32950 non-null  object \n",
      "dtypes: float32(1), float64(1), object(1)\n",
      "memory usage: 643.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Getting the info of the Training dataframe of the  Stacking Classifier\n",
    "df_train_stack.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the True Column to the int type\n",
    "df_train_stack['True'] = df_train_stack['True'].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32950 entries, 0 to 32949\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Voting  32950 non-null  float64\n",
      " 1   Neural  32950 non-null  float32\n",
      " 2   True    32950 non-null  int8   \n",
      "dtypes: float32(1), float64(1), int8(1)\n",
      "memory usage: 418.4 KB\n"
     ]
    }
   ],
   "source": [
    "# Re-checking the info of the df_train_stack\n",
    "df_train_stack.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Voting</th>\n",
       "      <th>Neural</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.254285</td>\n",
       "      <td>0.320342</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.274904</td>\n",
       "      <td>0.356925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.897182</td>\n",
       "      <td>0.964222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.210015</td>\n",
       "      <td>0.224473</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.831096</td>\n",
       "      <td>0.877714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Voting    Neural  True\n",
       "0  0.254285  0.320342     0\n",
       "1  0.274904  0.356925     0\n",
       "2  0.897182  0.964222     1\n",
       "3  0.210015  0.224473     0\n",
       "4  0.831096  0.877714     0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the top 5 rows of the df_train_stack\n",
    "df_train_stack.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Random forest as the Stacking classifier as it has one of highest  test set roc_auc as well as R_R ratio for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the hyperparameters of the Random Forest on the Stacked Training set using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the class weights\n",
    "cl_weight = [None,'balanced',{0:1.0,1:9.0},{0:1.0,1:10},{0:1.0,1:11},{0:1.0,1:12},{0:1.0,1:13},{0:1.0,1:14},{0:1.0,1:15}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the appropriate objective function for the Random Forest classifier\n",
    "def objective_wrappper_rf(X_tr, y_tr, cls=None, cv_strat=None):\n",
    "    '''\n",
    "    Optimizes Random Forest parameters on the given training set X_tr,y_tr\n",
    "    using cv_strat cross-validation object\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def objective(trial):\n",
    "        params = {\n",
    "        'max_depth': trial.suggest_categorical('max_depth',list(range(2,50))+ [None]),\n",
    "        'n_estimators':trial.suggest_int('n_estimators',100,2000,10),\n",
    "        'class_weight':trial.suggest_categorical('class_weight',cl_weight),\n",
    "        'min_samples_leaf':trial.suggest_loguniform('min_samples_leaf',.00001,.1)\n",
    "          }\n",
    "        \n",
    "        cls.set_params(**params)#Initializing the model with the parameters \n",
    "    \n",
    "        return np.mean(cross_val_score(cls, X_tr, y_tr, cv=cv_strat, n_jobs=5, scoring='roc_auc'))  \n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing  hyperparamater tuning optimizer optuna\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the evaluation function for study's best parameters\n",
    "def train_test_roc_auc(X_tr, y_tr, cls, obj_func, cv_strat, n_trials=100):\n",
    "    ''' Computes the best hyper parameters of the classsifier and returns \n",
    "    Optuna's study's best score & clasifier parameters'''\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(obj_func(X_tr, y_tr, cls, cv_strat), n_trials)\n",
    "    best_score = study.best_value\n",
    "    best_params = study.best_params\n",
    "    return (best_score,best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Random Forest Classifier from  Sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the Random forest classifier\n",
    "rf_s = RandomForestClassifier(n_jobs=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segregating the Features and class labels from the Training Dataset\n",
    "X_train_stacked = df_train_stack[['Voting','Neural']]\n",
    "y_train_stacked = df_train_stack['True']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-02 23:21:05,923]\u001b[0m A new study created in memory with name: no-name-a5025eef-ac4f-4eff-8a7c-49889c4619e2\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:21:35,831]\u001b[0m Trial 0 finished with value: 0.7985677591660422 and parameters: {'max_depth': 29, 'n_estimators': 1550, 'class_weight': {0: 1.0, 1: 11}, 'min_samples_leaf': 0.019211420621720456}. Best is trial 0 with value: 0.7985677591660422.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:22:47,841]\u001b[0m Trial 1 finished with value: 0.7776684448984348 and parameters: {'max_depth': 15, 'n_estimators': 1770, 'class_weight': {0: 1.0, 1: 10}, 'min_samples_leaf': 0.0001329767801953648}. Best is trial 0 with value: 0.7985677591660422.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:23:54,335]\u001b[0m Trial 2 finished with value: 0.7563436594490136 and parameters: {'max_depth': 47, 'n_estimators': 1280, 'class_weight': {0: 1.0, 1: 12}, 'min_samples_leaf': 1.0294047801488418e-05}. Best is trial 0 with value: 0.7985677591660422.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:24:26,329]\u001b[0m Trial 3 finished with value: 0.798273494147217 and parameters: {'max_depth': 42, 'n_estimators': 1480, 'class_weight': {0: 1.0, 1: 11}, 'min_samples_leaf': 0.016124409876656733}. Best is trial 0 with value: 0.7985677591660422.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:25:12,124]\u001b[0m Trial 4 finished with value: 0.7942900084916324 and parameters: {'max_depth': 10, 'n_estimators': 1510, 'class_weight': {0: 1.0, 1: 14}, 'min_samples_leaf': 0.0009003499595740142}. Best is trial 0 with value: 0.7985677591660422.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:25:34,460]\u001b[0m Trial 5 finished with value: 0.800206114248191 and parameters: {'max_depth': 4, 'n_estimators': 1290, 'class_weight': {0: 1.0, 1: 14}, 'min_samples_leaf': 4.303197843069858e-05}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:25:53,547]\u001b[0m Trial 6 finished with value: 0.7920475527983287 and parameters: {'max_depth': 9, 'n_estimators': 1360, 'class_weight': {0: 1.0, 1: 10}, 'min_samples_leaf': 0.08061974230682532}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:26:13,545]\u001b[0m Trial 7 finished with value: 0.7980592625565092 and parameters: {'max_depth': 36, 'n_estimators': 890, 'class_weight': {0: 1.0, 1: 13}, 'min_samples_leaf': 0.013605536898109144}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:26:15,987]\u001b[0m Trial 8 finished with value: 0.7940177630258609 and parameters: {'max_depth': 36, 'n_estimators': 150, 'class_weight': None, 'min_samples_leaf': 0.07521242868540318}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:26:26,032]\u001b[0m Trial 9 finished with value: 0.8001237631021636 and parameters: {'max_depth': 3, 'n_estimators': 680, 'class_weight': {0: 1.0, 1: 13}, 'min_samples_leaf': 5.369351301390868e-05}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:26:59,684]\u001b[0m Trial 10 finished with value: 0.8001645698735913 and parameters: {'max_depth': 4, 'n_estimators': 1960, 'class_weight': 'balanced', 'min_samples_leaf': 1.0905882317065297e-05}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:28:41,162]\u001b[0m Trial 11 finished with value: 0.7592840476687412 and parameters: {'max_depth': 26, 'n_estimators': 2000, 'class_weight': 'balanced', 'min_samples_leaf': 1.1700107196291926e-05}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:29:14,753]\u001b[0m Trial 12 finished with value: 0.8001868959084735 and parameters: {'max_depth': 4, 'n_estimators': 1960, 'class_weight': {0: 1.0, 1: 14}, 'min_samples_leaf': 5.577688422660956e-05}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:29:22,741]\u001b[0m Trial 13 finished with value: 0.8001763272594946 and parameters: {'max_depth': 4, 'n_estimators': 460, 'class_weight': {0: 1.0, 1: 14}, 'min_samples_leaf': 0.000128168518578979}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:30:05,490]\u001b[0m Trial 14 finished with value: 0.7877377838709871 and parameters: {'max_depth': 45, 'n_estimators': 1060, 'class_weight': {0: 1.0, 1: 14}, 'min_samples_leaf': 0.0009131224259455874}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:31:30,663]\u001b[0m Trial 15 finished with value: 0.7653344076051715 and parameters: {'max_depth': 28, 'n_estimators': 1720, 'class_weight': {0: 1.0, 1: 9.0}, 'min_samples_leaf': 4.438257327984599e-05}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:32:19,796]\u001b[0m Trial 16 finished with value: 0.7796649622234499 and parameters: {'max_depth': 41, 'n_estimators': 1080, 'class_weight': {0: 1.0, 1: 15}, 'min_samples_leaf': 0.00027222597573577903}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:32:51,781]\u001b[0m Trial 17 finished with value: 0.800200905717712 and parameters: {'max_depth': 4, 'n_estimators': 1840, 'class_weight': {0: 1.0, 1: 14}, 'min_samples_leaf': 2.9855856998313048e-05}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:33:58,191]\u001b[0m Trial 18 finished with value: 0.774099443752186 and parameters: {'max_depth': 13, 'n_estimators': 1750, 'class_weight': {0: 1.0, 1: 14}, 'min_samples_leaf': 2.4811384252743045e-05}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:34:33,892]\u001b[0m Trial 19 finished with value: 0.7955861265113187 and parameters: {'max_depth': 18, 'n_estimators': 1220, 'class_weight': {0: 1.0, 1: 15}, 'min_samples_leaf': 0.0042861771738697185}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:35:06,613]\u001b[0m Trial 20 finished with value: 0.7817101592997562 and parameters: {'max_depth': 43, 'n_estimators': 720, 'class_weight': {0: 1.0, 1: 14}, 'min_samples_leaf': 0.00039288770819052637}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:35:41,513]\u001b[0m Trial 21 finished with value: 0.8001791981245935 and parameters: {'max_depth': 4, 'n_estimators': 2000, 'class_weight': {0: 1.0, 1: 14}, 'min_samples_leaf': 3.012256507590905e-05}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:37:13,662]\u001b[0m Trial 22 finished with value: 0.7675422591700002 and parameters: {'max_depth': 37, 'n_estimators': 1850, 'class_weight': {0: 1.0, 1: 14}, 'min_samples_leaf': 9.862739100798515e-05}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:37:46,584]\u001b[0m Trial 23 finished with value: 0.799764776720387 and parameters: {'max_depth': 5, 'n_estimators': 1660, 'class_weight': {0: 1.0, 1: 14}, 'min_samples_leaf': 2.022937628217229e-05}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:39:24,739]\u001b[0m Trial 24 finished with value: 0.7617563281694597 and parameters: {'max_depth': 46, 'n_estimators': 1940, 'class_weight': {0: 1.0, 1: 9.0}, 'min_samples_leaf': 6.673003221687883e-05}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:40:36,775]\u001b[0m Trial 25 finished with value: 0.7816249409796419 and parameters: {'max_depth': 33, 'n_estimators': 1600, 'class_weight': {0: 1.0, 1: 12}, 'min_samples_leaf': 0.00035597769422310006}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:41:48,907]\u001b[0m Trial 26 finished with value: 0.7687616838302539 and parameters: {'max_depth': 23, 'n_estimators': 1370, 'class_weight': None, 'min_samples_leaf': 1.916488502480175e-05}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:43:14,620]\u001b[0m Trial 27 finished with value: 0.777201758090813 and parameters: {'max_depth': 39, 'n_estimators': 1830, 'class_weight': {0: 1.0, 1: 14}, 'min_samples_leaf': 0.0002170038636398992}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:43:41,679]\u001b[0m Trial 28 finished with value: 0.7962637849687637 and parameters: {'max_depth': 11, 'n_estimators': 890, 'class_weight': {0: 1.0, 1: 14}, 'min_samples_leaf': 0.0025769182435544293}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:44:55,292]\u001b[0m Trial 29 finished with value: 0.7659001469999339 and parameters: {'max_depth': 22, 'n_estimators': 1520, 'class_weight': {0: 1.0, 1: 11}, 'min_samples_leaf': 3.67128239440495e-05}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:45:45,849]\u001b[0m Trial 30 finished with value: 0.770317804093356 and parameters: {'max_depth': 17, 'n_estimators': 1190, 'class_weight': {0: 1.0, 1: 14}, 'min_samples_leaf': 7.905463154652744e-05}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-02 23:46:18,847]\u001b[0m Trial 31 finished with value: 0.8001869688358418 and parameters: {'max_depth': 4, 'n_estimators': 1910, 'class_weight': {0: 1.0, 1: 14}, 'min_samples_leaf': 2.6692206671107163e-05}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:46:50,828]\u001b[0m Trial 32 finished with value: 0.8001821201652017 and parameters: {'max_depth': 4, 'n_estimators': 1860, 'class_weight': {0: 1.0, 1: 14}, 'min_samples_leaf': 1.290102664864045e-05}. Best is trial 5 with value: 0.800206114248191.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:47:19,771]\u001b[0m Trial 33 finished with value: 0.8002590206328056 and parameters: {'max_depth': 4, 'n_estimators': 1670, 'class_weight': {0: 1.0, 1: 10}, 'min_samples_leaf': 0.0001593845377949925}. Best is trial 33 with value: 0.8002590206328056.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:48:21,798]\u001b[0m Trial 34 finished with value: 0.7776296136132248 and parameters: {'max_depth': 21, 'n_estimators': 1390, 'class_weight': {0: 1.0, 1: 10}, 'min_samples_leaf': 0.00018457452393199825}. Best is trial 33 with value: 0.8002590206328056.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:49:02,826]\u001b[0m Trial 35 finished with value: 0.798049340072491 and parameters: {'max_depth': 7, 'n_estimators': 1650, 'class_weight': {0: 1.0, 1: 10}, 'min_samples_leaf': 0.00046699761229482994}. Best is trial 33 with value: 0.8002590206328056.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:50:15,128]\u001b[0m Trial 36 finished with value: 0.7706192822064691 and parameters: {'max_depth': 40, 'n_estimators': 1470, 'class_weight': {0: 1.0, 1: 10}, 'min_samples_leaf': 0.00010413516569670118}. Best is trial 33 with value: 0.8002590206328056.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:51:47,445]\u001b[0m Trial 37 finished with value: 0.7553316128684765 and parameters: {'max_depth': None, 'n_estimators': 1750, 'class_weight': {0: 1.0, 1: 12}, 'min_samples_leaf': 1.942683600937795e-05}. Best is trial 33 with value: 0.8002590206328056.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:53:00,818]\u001b[0m Trial 38 finished with value: 0.7612251323640666 and parameters: {'max_depth': 19, 'n_estimators': 1580, 'class_weight': {0: 1.0, 1: 10}, 'min_samples_leaf': 3.215554340487563e-05}. Best is trial 33 with value: 0.8002590206328056.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:53:15,858]\u001b[0m Trial 39 finished with value: 0.7989802073211208 and parameters: {'max_depth': 2, 'n_estimators': 1310, 'class_weight': {0: 1.0, 1: 11}, 'min_samples_leaf': 0.0001597492831106573}. Best is trial 33 with value: 0.8002590206328056.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:53:53,740]\u001b[0m Trial 40 finished with value: 0.797797345781218 and parameters: {'max_depth': 8, 'n_estimators': 1450, 'class_weight': {0: 1.0, 1: 13}, 'min_samples_leaf': 0.0018983001497635272}. Best is trial 33 with value: 0.8002590206328056.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:54:26,714]\u001b[0m Trial 41 finished with value: 0.8001834317069006 and parameters: {'max_depth': 4, 'n_estimators': 1920, 'class_weight': {0: 1.0, 1: 14}, 'min_samples_leaf': 5.31940236416359e-05}. Best is trial 33 with value: 0.8002590206328056.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:54:58,258]\u001b[0m Trial 42 finished with value: 0.8003822305738767 and parameters: {'max_depth': 4, 'n_estimators': 1830, 'class_weight': None, 'min_samples_leaf': 7.618459505939218e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:56:33,358]\u001b[0m Trial 43 finished with value: 0.7575409160923867 and parameters: {'max_depth': 49, 'n_estimators': 1660, 'class_weight': None, 'min_samples_leaf': 1.4152434523827346e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:58:05,470]\u001b[0m Trial 44 finished with value: 0.7695428340547653 and parameters: {'max_depth': 35, 'n_estimators': 1710, 'class_weight': None, 'min_samples_leaf': 9.725826464274256e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-02 23:59:43,678]\u001b[0m Trial 45 finished with value: 0.770221862637214 and parameters: {'max_depth': 25, 'n_estimators': 1840, 'class_weight': None, 'min_samples_leaf': 3.963714770313931e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:00:45,460]\u001b[0m Trial 46 finished with value: 0.7919747547051814 and parameters: {'max_depth': 12, 'n_estimators': 1800, 'class_weight': 'balanced', 'min_samples_leaf': 0.0005982678408382545}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:02:19,913]\u001b[0m Trial 47 finished with value: 0.7673482197638963 and parameters: {'max_depth': 38, 'n_estimators': 1910, 'class_weight': {0: 1.0, 1: 10}, 'min_samples_leaf': 6.778787565728405e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:02:53,883]\u001b[0m Trial 48 finished with value: 0.8003821066959969 and parameters: {'max_depth': 4, 'n_estimators': 2000, 'class_weight': None, 'min_samples_leaf': 0.00013998009618379975}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:03:49,883]\u001b[0m Trial 49 finished with value: 0.7753090425631104 and parameters: {'max_depth': 34, 'n_estimators': 1130, 'class_weight': None, 'min_samples_leaf': 0.00014317437551344256}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:03:59,023]\u001b[0m Trial 50 finished with value: 0.7807008881307398 and parameters: {'max_depth': 44, 'n_estimators': 190, 'class_weight': None, 'min_samples_leaf': 0.00028449541955125464}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:04:32,966]\u001b[0m Trial 51 finished with value: 0.8002881693058544 and parameters: {'max_depth': 4, 'n_estimators': 2000, 'class_weight': None, 'min_samples_leaf': 1.0340851132954598e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:05:07,235]\u001b[0m Trial 52 finished with value: 0.8003308264611043 and parameters: {'max_depth': 4, 'n_estimators': 1990, 'class_weight': None, 'min_samples_leaf': 4.896201032095139e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:05:28,548]\u001b[0m Trial 53 finished with value: 0.799919743740669 and parameters: {'max_depth': 6, 'n_estimators': 940, 'class_weight': None, 'min_samples_leaf': 1.0473925923779352e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:07:11,899]\u001b[0m Trial 54 finished with value: 0.7725401384181427 and parameters: {'max_depth': 48, 'n_estimators': 1990, 'class_weight': None, 'min_samples_leaf': 0.00012012455451576674}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:07:41,708]\u001b[0m Trial 55 finished with value: 0.8003641051192233 and parameters: {'max_depth': 4, 'n_estimators': 1750, 'class_weight': None, 'min_samples_leaf': 4.897836478293798e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:09:09,845]\u001b[0m Trial 56 finished with value: 0.7860315370108182 and parameters: {'max_depth': 30, 'n_estimators': 2000, 'class_weight': None, 'min_samples_leaf': 0.000566214319909081}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:10:33,368]\u001b[0m Trial 57 finished with value: 0.7801985092854682 and parameters: {'max_depth': 31, 'n_estimators': 1770, 'class_weight': None, 'min_samples_leaf': 0.000255787387623648}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:12:07,987]\u001b[0m Trial 58 finished with value: 0.777605772234767 and parameters: {'max_depth': 20, 'n_estimators': 1990, 'class_weight': None, 'min_samples_leaf': 7.532053114855778e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:12:36,896]\u001b[0m Trial 59 finished with value: 0.8003632754762646 and parameters: {'max_depth': 4, 'n_estimators': 1700, 'class_weight': None, 'min_samples_leaf': 4.309146997615968e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:13:59,010]\u001b[0m Trial 60 finished with value: 0.782511617490907 and parameters: {'max_depth': 16, 'n_estimators': 1890, 'class_weight': None, 'min_samples_leaf': 4.761155546361411e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:14:27,814]\u001b[0m Trial 61 finished with value: 0.8003632754762646 and parameters: {'max_depth': 4, 'n_estimators': 1700, 'class_weight': None, 'min_samples_leaf': 5.574722159164947e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-03 00:14:58,363]\u001b[0m Trial 62 finished with value: 0.8002905028605773 and parameters: {'max_depth': 4, 'n_estimators': 1770, 'class_weight': None, 'min_samples_leaf': 1.9011795186684577e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:16:03,315]\u001b[0m Trial 63 finished with value: 0.7875491072962408 and parameters: {'max_depth': 14, 'n_estimators': 1570, 'class_weight': None, 'min_samples_leaf': 1.9150608464861085e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:17:38,816]\u001b[0m Trial 64 finished with value: 0.7664606536460319 and parameters: {'max_depth': 32, 'n_estimators': 1790, 'class_weight': None, 'min_samples_leaf': 5.2109315566479745e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:19:13,028]\u001b[0m Trial 65 finished with value: 0.7643837311122572 and parameters: {'max_depth': 27, 'n_estimators': 1710, 'class_weight': None, 'min_samples_leaf': 2.4904965238943712e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:20:31,910]\u001b[0m Trial 66 finished with value: 0.7688178072402162 and parameters: {'max_depth': 29, 'n_estimators': 1610, 'class_weight': {0: 1.0, 1: 15}, 'min_samples_leaf': 8.318838403538761e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:21:03,232]\u001b[0m Trial 67 finished with value: 0.8003504710802231 and parameters: {'max_depth': 4, 'n_estimators': 1790, 'class_weight': None, 'min_samples_leaf': 3.842848999654642e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:22:18,378]\u001b[0m Trial 68 finished with value: 0.7623300103258962 and parameters: {'max_depth': 42, 'n_estimators': 1510, 'class_weight': {0: 1.0, 1: 9.0}, 'min_samples_leaf': 4.191876616649131e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:22:50,868]\u001b[0m Trial 69 finished with value: 0.7984007114849335 and parameters: {'max_depth': 24, 'n_estimators': 1870, 'class_weight': None, 'min_samples_leaf': 0.04542886910127778}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:23:19,725]\u001b[0m Trial 70 finished with value: 0.8003626842946471 and parameters: {'max_depth': 4, 'n_estimators': 1690, 'class_weight': None, 'min_samples_leaf': 5.737320097245792e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:23:48,778]\u001b[0m Trial 71 finished with value: 0.8003578929655015 and parameters: {'max_depth': 4, 'n_estimators': 1710, 'class_weight': None, 'min_samples_leaf': 3.5237783014341234e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:24:17,542]\u001b[0m Trial 72 finished with value: 0.8003632754762646 and parameters: {'max_depth': 4, 'n_estimators': 1700, 'class_weight': None, 'min_samples_leaf': 6.562737300090031e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:25:44,249]\u001b[0m Trial 73 finished with value: 0.7646077211155798 and parameters: {'max_depth': 47, 'n_estimators': 1620, 'class_weight': None, 'min_samples_leaf': 6.30843599698888e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:26:39,543]\u001b[0m Trial 74 finished with value: 0.795558725126903 and parameters: {'max_depth': 10, 'n_estimators': 1730, 'class_weight': None, 'min_samples_leaf': 0.00011026271306163972}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:27:04,406]\u001b[0m Trial 75 finished with value: 0.8002287747044493 and parameters: {'max_depth': 4, 'n_estimators': 1430, 'class_weight': {0: 1.0, 1: 13}, 'min_samples_leaf': 2.97104618095321e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:28:12,914]\u001b[0m Trial 76 finished with value: 0.7773633902114356 and parameters: {'max_depth': 15, 'n_estimators': 1680, 'class_weight': 'balanced', 'min_samples_leaf': 8.468275888672474e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:28:57,723]\u001b[0m Trial 77 finished with value: 0.7913789260760205 and parameters: {'max_depth': 9, 'n_estimators': 1540, 'class_weight': {0: 1.0, 1: 12}, 'min_samples_leaf': 1.4071740957587312e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:29:25,200]\u001b[0m Trial 78 finished with value: 0.8003587699978377 and parameters: {'max_depth': 4, 'n_estimators': 1620, 'class_weight': None, 'min_samples_leaf': 6.040467158536359e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:29:48,472]\u001b[0m Trial 79 finished with value: 0.800058010955351 and parameters: {'max_depth': 3, 'n_estimators': 1630, 'class_weight': {0: 1.0, 1: 11}, 'min_samples_leaf': 0.0002033456350871607}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:30:19,374]\u001b[0m Trial 80 finished with value: 0.8003334142793923 and parameters: {'max_depth': 4, 'n_estimators': 1820, 'class_weight': None, 'min_samples_leaf': 6.500882068735378e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:30:48,147]\u001b[0m Trial 81 finished with value: 0.8003632754762646 and parameters: {'max_depth': 4, 'n_estimators': 1700, 'class_weight': None, 'min_samples_leaf': 3.817660956255962e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:32:15,160]\u001b[0m Trial 82 finished with value: 0.7699284448766079 and parameters: {'max_depth': 26, 'n_estimators': 1680, 'class_weight': None, 'min_samples_leaf': 5.541702124079023e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:32:41,738]\u001b[0m Trial 83 finished with value: 0.8003342649083365 and parameters: {'max_depth': 4, 'n_estimators': 1560, 'class_weight': None, 'min_samples_leaf': 2.4218238173682963e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:34:20,746]\u001b[0m Trial 84 finished with value: 0.7729122596407971 and parameters: {'max_depth': 36, 'n_estimators': 1940, 'class_weight': None, 'min_samples_leaf': 0.00012633422530505006}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:35:38,421]\u001b[0m Trial 85 finished with value: 0.7690569660720449 and parameters: {'max_depth': 45, 'n_estimators': 1490, 'class_weight': None, 'min_samples_leaf': 8.277846692519119e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:36:07,935]\u001b[0m Trial 86 finished with value: 0.8002234838440083 and parameters: {'max_depth': 4, 'n_estimators': 1740, 'class_weight': {0: 1.0, 1: 15}, 'min_samples_leaf': 9.483425235532893e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:36:38,872]\u001b[0m Trial 87 finished with value: 0.800252016822909 and parameters: {'max_depth': 4, 'n_estimators': 1830, 'class_weight': {0: 1.0, 1: 9.0}, 'min_samples_leaf': 6.122171126696114e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:38:04,264]\u001b[0m Trial 88 finished with value: 0.7647217801384038 and parameters: {'max_depth': 43, 'n_estimators': 1600, 'class_weight': None, 'min_samples_leaf': 4.4306117145847065e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:39:37,717]\u001b[0m Trial 89 finished with value: 0.7761413984250433 and parameters: {'max_depth': 28, 'n_estimators': 1890, 'class_weight': None, 'min_samples_leaf': 0.00015165904845608128}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:41:11,071]\u001b[0m Trial 90 finished with value: 0.7579050677432161 and parameters: {'max_depth': 46, 'n_estimators': 1650, 'class_weight': None, 'min_samples_leaf': 3.23929557746333e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:41:40,014]\u001b[0m Trial 91 finished with value: 0.8003632754762646 and parameters: {'max_depth': 4, 'n_estimators': 1700, 'class_weight': None, 'min_samples_leaf': 3.5484784413083676e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:42:09,458]\u001b[0m Trial 92 finished with value: 0.800299819572384 and parameters: {'max_depth': 4, 'n_estimators': 1730, 'class_weight': None, 'min_samples_leaf': 1.6138743518776678e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:43:34,136]\u001b[0m Trial 93 finished with value: 0.7770085960805684 and parameters: {'max_depth': 18, 'n_estimators': 1800, 'class_weight': None, 'min_samples_leaf': 2.556019534429579e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-03 00:45:03,207]\u001b[0m Trial 94 finished with value: 0.7650595685705328 and parameters: {'max_depth': 41, 'n_estimators': 1670, 'class_weight': None, 'min_samples_leaf': 3.903491920463432e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:45:29,480]\u001b[0m Trial 95 finished with value: 0.8003767314243238 and parameters: {'max_depth': 4, 'n_estimators': 1540, 'class_weight': None, 'min_samples_leaf': 7.42733310028795e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:45:55,725]\u001b[0m Trial 96 finished with value: 0.8003767314243238 and parameters: {'max_depth': 4, 'n_estimators': 1540, 'class_weight': None, 'min_samples_leaf': 7.451495640090427e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:46:47,576]\u001b[0m Trial 97 finished with value: 0.7805602412739591 and parameters: {'max_depth': 13, 'n_estimators': 1410, 'class_weight': {0: 1.0, 1: 12}, 'min_samples_leaf': 0.00010623144067744437}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:47:48,516]\u001b[0m Trial 98 finished with value: 0.7798618416301364 and parameters: {'max_depth': 22, 'n_estimators': 1320, 'class_weight': None, 'min_samples_leaf': 0.00017567101108747888}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:48:52,979]\u001b[0m Trial 99 finished with value: 0.7711473523986141 and parameters: {'max_depth': 17, 'n_estimators': 1540, 'class_weight': {0: 1.0, 1: 13}, 'min_samples_leaf': 7.266245226128673e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:49:24,439]\u001b[0m Trial 100 finished with value: 0.8002037867339838 and parameters: {'max_depth': 4, 'n_estimators': 1870, 'class_weight': 'balanced', 'min_samples_leaf': 0.0001341741131203276}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:49:54,395]\u001b[0m Trial 101 finished with value: 0.8003549366333601 and parameters: {'max_depth': 4, 'n_estimators': 1770, 'class_weight': None, 'min_samples_leaf': 4.8885667351964173e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:50:44,149]\u001b[0m Trial 102 finished with value: 0.7943102782853181 and parameters: {'max_depth': 11, 'n_estimators': 1460, 'class_weight': None, 'min_samples_leaf': 3.4659425160117014e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:52:12,944]\u001b[0m Trial 103 finished with value: 0.7695822981386884 and parameters: {'max_depth': 37, 'n_estimators': 1700, 'class_weight': None, 'min_samples_leaf': 7.129924981934067e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:52:44,247]\u001b[0m Trial 104 finished with value: 0.8002511608242029 and parameters: {'max_depth': 5, 'n_estimators': 1580, 'class_weight': None, 'min_samples_leaf': 9.1981925843557e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:54:19,055]\u001b[0m Trial 105 finished with value: 0.7658409456255181 and parameters: {'max_depth': 33, 'n_estimators': 1750, 'class_weight': None, 'min_samples_leaf': 4.3442945058002445e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:55:32,615]\u001b[0m Trial 106 finished with value: 0.7578695053557281 and parameters: {'max_depth': 23, 'n_estimators': 1510, 'class_weight': {0: 1.0, 1: 11}, 'min_samples_leaf': 2.1916848782806018e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:57:16,382]\u001b[0m Trial 107 finished with value: 0.7650625290782702 and parameters: {'max_depth': 39, 'n_estimators': 1940, 'class_weight': None, 'min_samples_leaf': 5.226171718761201e-05}. Best is trial 42 with value: 0.8003822305738767.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:57:44,492]\u001b[0m Trial 108 finished with value: 0.8003847112814382 and parameters: {'max_depth': 4, 'n_estimators': 1650, 'class_weight': None, 'min_samples_leaf': 0.00011628289411761268}. Best is trial 108 with value: 0.8003847112814382.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:58:11,837]\u001b[0m Trial 109 finished with value: 0.8002514073769799 and parameters: {'max_depth': 4, 'n_estimators': 1640, 'class_weight': None, 'min_samples_leaf': 0.00849605489825757}. Best is trial 108 with value: 0.8003847112814382.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 00:59:43,674]\u001b[0m Trial 110 finished with value: 0.7715743373837785 and parameters: {'max_depth': 21, 'n_estimators': 1820, 'class_weight': None, 'min_samples_leaf': 2.9262132278662394e-05}. Best is trial 108 with value: 0.8003847112814382.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:00:12,493]\u001b[0m Trial 111 finished with value: 0.8003817188101383 and parameters: {'max_depth': 4, 'n_estimators': 1690, 'class_weight': None, 'min_samples_leaf': 0.00011267054937298183}. Best is trial 108 with value: 0.8003847112814382.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:00:39,224]\u001b[0m Trial 112 finished with value: 0.8003836581053141 and parameters: {'max_depth': 4, 'n_estimators': 1580, 'class_weight': None, 'min_samples_leaf': 0.00011702423154205118}. Best is trial 108 with value: 0.8003847112814382.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:02:00,627]\u001b[0m Trial 113 finished with value: 0.7725404148835622 and parameters: {'max_depth': 40, 'n_estimators': 1590, 'class_weight': None, 'min_samples_leaf': 0.00011040248503529947}. Best is trial 108 with value: 0.8003847112814382.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:02:26,866]\u001b[0m Trial 114 finished with value: 0.8004241337179158 and parameters: {'max_depth': 4, 'n_estimators': 1540, 'class_weight': None, 'min_samples_leaf': 0.00024403747920277233}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:03:34,829]\u001b[0m Trial 115 finished with value: 0.7833631035384296 and parameters: {'max_depth': 19, 'n_estimators': 1540, 'class_weight': None, 'min_samples_leaf': 0.000241977386780609}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:04:07,758]\u001b[0m Trial 116 finished with value: 0.7972371669103349 and parameters: {'max_depth': 7, 'n_estimators': 1350, 'class_weight': {0: 1.0, 1: 15}, 'min_samples_leaf': 0.00033811949904662873}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:05:18,331]\u001b[0m Trial 117 finished with value: 0.777074035557864 and parameters: {'max_depth': None, 'n_estimators': 1440, 'class_weight': None, 'min_samples_leaf': 0.0001695405813093776}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:05:35,179]\u001b[0m Trial 118 finished with value: 0.7974527079787659 and parameters: {'max_depth': 2, 'n_estimators': 1490, 'class_weight': None, 'min_samples_leaf': 0.0001257875395795911}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:06:03,087]\u001b[0m Trial 119 finished with value: 0.8004084328192566 and parameters: {'max_depth': 4, 'n_estimators': 1640, 'class_weight': None, 'min_samples_leaf': 0.00021000009173663826}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:06:24,742]\u001b[0m Trial 120 finished with value: 0.8002259106630341 and parameters: {'max_depth': 4, 'n_estimators': 1270, 'class_weight': {0: 1.0, 1: 9.0}, 'min_samples_leaf': 0.00021193924649185594}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:06:52,650]\u001b[0m Trial 121 finished with value: 0.8004094681464753 and parameters: {'max_depth': 4, 'n_estimators': 1640, 'class_weight': None, 'min_samples_leaf': 0.00029637015464662353}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:07:20,263]\u001b[0m Trial 122 finished with value: 0.8004017284901519 and parameters: {'max_depth': 4, 'n_estimators': 1620, 'class_weight': None, 'min_samples_leaf': 0.00027438169733220346}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:07:46,908]\u001b[0m Trial 123 finished with value: 0.8003697953580341 and parameters: {'max_depth': 4, 'n_estimators': 1560, 'class_weight': None, 'min_samples_leaf': 0.000490135640626209}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:08:28,966]\u001b[0m Trial 124 finished with value: 0.7980328529437106 and parameters: {'max_depth': 8, 'n_estimators': 1570, 'class_weight': None, 'min_samples_leaf': 0.0007513092855999347}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:09:44,601]\u001b[0m Trial 125 finished with value: 0.7832726057076213 and parameters: {'max_depth': 49, 'n_estimators': 1640, 'class_weight': None, 'min_samples_leaf': 0.0003740710164887723}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-11-03 01:10:54,733]\u001b[0m Trial 126 finished with value: 0.7816768310326337 and parameters: {'max_depth': 35, 'n_estimators': 1520, 'class_weight': None, 'min_samples_leaf': 0.00030661798319488274}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:12:05,869]\u001b[0m Trial 127 finished with value: 0.7846403804556144 and parameters: {'max_depth': 25, 'n_estimators': 1600, 'class_weight': None, 'min_samples_leaf': 0.0004242877359032014}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:13:20,185]\u001b[0m Trial 128 finished with value: 0.7785927046868022 and parameters: {'max_depth': 38, 'n_estimators': 1550, 'class_weight': None, 'min_samples_leaf': 0.00022293034694246362}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:14:18,056]\u001b[0m Trial 129 finished with value: 0.7907258934965208 and parameters: {'max_depth': 44, 'n_estimators': 1480, 'class_weight': None, 'min_samples_leaf': 0.0012446029184334678}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:14:41,576]\u001b[0m Trial 130 finished with value: 0.8002671577030508 and parameters: {'max_depth': 4, 'n_estimators': 1390, 'class_weight': {0: 1.0, 1: 12}, 'min_samples_leaf': 0.0004757029263330948}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:15:09,378]\u001b[0m Trial 131 finished with value: 0.8004094681464753 and parameters: {'max_depth': 4, 'n_estimators': 1640, 'class_weight': None, 'min_samples_leaf': 0.000283120508544278}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:15:37,009]\u001b[0m Trial 132 finished with value: 0.800401357812795 and parameters: {'max_depth': 4, 'n_estimators': 1630, 'class_weight': None, 'min_samples_leaf': 0.00029325714303886114}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:16:04,595]\u001b[0m Trial 133 finished with value: 0.8004017284901519 and parameters: {'max_depth': 4, 'n_estimators': 1620, 'class_weight': None, 'min_samples_leaf': 0.0002880064488052529}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:17:21,170]\u001b[0m Trial 134 finished with value: 0.7808775735787833 and parameters: {'max_depth': 48, 'n_estimators': 1640, 'class_weight': None, 'min_samples_leaf': 0.00028152155114208517}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:18:36,821]\u001b[0m Trial 135 finished with value: 0.7760320769465959 and parameters: {'max_depth': 34, 'n_estimators': 1620, 'class_weight': {0: 1.0, 1: 13}, 'min_samples_leaf': 0.0001892368172408939}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:19:33,415]\u001b[0m Trial 136 finished with value: 0.7922375771273493 and parameters: {'max_depth': 12, 'n_estimators': 1600, 'class_weight': None, 'min_samples_leaf': 0.0002525565014279965}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:19:47,310]\u001b[0m Trial 137 finished with value: 0.7987385871366106 and parameters: {'max_depth': 6, 'n_estimators': 620, 'class_weight': {0: 1.0, 1: 10}, 'min_samples_leaf': 0.00015654748601961582}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:20:15,382]\u001b[0m Trial 138 finished with value: 0.8003599417858466 and parameters: {'max_depth': 4, 'n_estimators': 1660, 'class_weight': None, 'min_samples_leaf': 0.0007475415761234172}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:21:19,502]\u001b[0m Trial 139 finished with value: 0.781786857683231 and parameters: {'max_depth': 31, 'n_estimators': 1450, 'class_weight': 'balanced', 'min_samples_leaf': 0.0003410561255048353}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:22:33,279]\u001b[0m Trial 140 finished with value: 0.77741151954179 and parameters: {'max_depth': 30, 'n_estimators': 1520, 'class_weight': None, 'min_samples_leaf': 0.00019147536446429233}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:22:59,759]\u001b[0m Trial 141 finished with value: 0.800356745252914 and parameters: {'max_depth': 4, 'n_estimators': 1550, 'class_weight': None, 'min_samples_leaf': 0.0005779520649335759}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:23:26,516]\u001b[0m Trial 142 finished with value: 0.8003816939384933 and parameters: {'max_depth': 4, 'n_estimators': 1570, 'class_weight': None, 'min_samples_leaf': 0.0004549643141679518}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:23:53,804]\u001b[0m Trial 143 finished with value: 0.8004203437403341 and parameters: {'max_depth': 4, 'n_estimators': 1600, 'class_weight': None, 'min_samples_leaf': 0.0002947314250624473}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:24:21,994]\u001b[0m Trial 144 finished with value: 0.8004191898358195 and parameters: {'max_depth': 4, 'n_estimators': 1660, 'class_weight': None, 'min_samples_leaf': 0.000258699135211398}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:25:28,031]\u001b[0m Trial 145 finished with value: 0.787497075477636 and parameters: {'max_depth': 16, 'n_estimators': 1620, 'class_weight': None, 'min_samples_leaf': 0.00030909317376312854}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:26:39,563]\u001b[0m Trial 146 finished with value: 0.7805127547118988 and parameters: {'max_depth': 20, 'n_estimators': 1660, 'class_weight': {0: 1.0, 1: 11}, 'min_samples_leaf': 0.00025339941015868557}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:27:09,500]\u001b[0m Trial 147 finished with value: 0.8003717809608355 and parameters: {'max_depth': 4, 'n_estimators': 1760, 'class_weight': None, 'min_samples_leaf': 0.000383099142228616}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:28:11,022]\u001b[0m Trial 148 finished with value: 0.7886960294020183 and parameters: {'max_depth': 14, 'n_estimators': 1590, 'class_weight': None, 'min_samples_leaf': 0.00022256137895093934}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n",
      "\u001b[32m[I 2020-11-03 01:29:33,031]\u001b[0m Trial 149 finished with value: 0.7767712016161659 and parameters: {'max_depth': 27, 'n_estimators': 1670, 'class_weight': None, 'min_samples_leaf': 0.00014562050758562062}. Best is trial 114 with value: 0.8004241337179158.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Extracting the best model parameters and best study score\n",
    "best_study_score,best_study_params = train_test_roc_auc(X_train_stacked, y_train_stacked, rf_s, objective_wrappper_rf, cv_strat, n_trials=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best roc_auc_score for the study is:  0.8004241337179158\n"
     ]
    }
   ],
   "source": [
    "print('The best roc_auc_score for the study is: ', best_study_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best study parameters for the classifier are:  {'max_depth': 4, 'n_estimators': 1540, 'class_weight': None, 'min_samples_leaf': 0.00024403747920277233}\n"
     ]
    }
   ],
   "source": [
    "print('The best study parameters for the classifier are: ', best_study_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining the best Stacking Random Forest model by setting best study parameters.\n",
    "rf_stack = rf_s.set_params(**best_study_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=4, min_samples_leaf=0.00024403747920277233,\n",
       "                       n_estimators=1540, n_jobs=5, random_state=42)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the best Stacking Random Forest model on the whole training set\n",
    "rf_stack.fit(X_train_stacked, y_train_stacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Test set observations for the Stacking Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('logistic_Reg',\n",
       "                              LogisticRegression(C=0.12725888493400458,\n",
       "                                                 class_weight={0: 1.0, 1: 9.0},\n",
       "                                                 l1_ratio=0.9851193622801032,\n",
       "                                                 n_jobs=5, penalty='elasticnet',\n",
       "                                                 random_state=42,\n",
       "                                                 solver='saga')),\n",
       "                             ('Random_Forest',\n",
       "                              RandomForestClassifier(class_weight='balanced',\n",
       "                                                     max_depth=11,\n",
       "                                                     min_samples_leaf=0.000264150675671259,\n",
       "                                                     n_estimators=1560,\n",
       "                                                     n_jobs=5,\n",
       "                                                     rando...\n",
       "                                             max_depth=85, min_child_samples=16,\n",
       "                                             n_estimators=1083, n_jobs=5,\n",
       "                                             num_leaves=26, objective='binary',\n",
       "                                             random_state=42,\n",
       "                                             reg_alpha=6.964534534541776,\n",
       "                                             reg_lambda=5.143496762382144)),\n",
       "                             ('Linear_Dis',\n",
       "                              LinearDiscriminantAnalysis(shrinkage=0.0023665526949698365,\n",
       "                                                         solver='eigen'))],\n",
       "                 n_jobs=5, voting='soft',\n",
       "                 weights=[0.01892659811471946, 0.12205104743904709,\n",
       "                          0.4097477051900742, 0.007396756446858069])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Voting Classifier on the whole Training set\n",
    "voting_clf.fit(X_train_red,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the predictions of the voting classifier on the test set.\n",
    "y_pred_test_voting = voting_clf.predict_proba(X_test_red)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reloading the best Neural Classifier\n",
    "neural = keras.models.load_model('Best_model_Selu_eq_Learn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the predictions of the Neural Classifier on the test set.\n",
    "y_pred_test_neural = neural.predict_proba(X_test_red).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the Test feature set for the Stacking Classifier\n",
    "X_test_stacked = pd.DataFrame({'Voting':y_pred_test_voting,'Neural':y_pred_test_neural})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8238 entries, 0 to 8237\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Voting  8238 non-null   float64\n",
      " 1   Neural  8238 non-null   float32\n",
      "dtypes: float32(1), float64(1)\n",
      "memory usage: 96.7 KB\n"
     ]
    }
   ],
   "source": [
    "# Checking the info of the Stacking Test Features\n",
    "X_test_stacked.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the Stacking Classifier Predictions for the Test set\n",
    "y_pred_stacked = rf_stack.predict_proba(X_test_stacked)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test set roc_auc score for the Stacking Classifier is:  0.8145040007783386\n"
     ]
    }
   ],
   "source": [
    "# Getting the stacking Clasiifier roc_auc score for the Test Set.\n",
    "print('The test set roc_auc score for the Stacking Classifier is: ',roc_auc_score(y_test,y_pred_stacked))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating R_R ratio for Stacking Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the CV scores using sklearn's cross_val_score\n",
    "score_Stacking = cross_val_score(rf_stack, X_train_stacked, y_train_stacked, cv=cv_strat, n_jobs=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reward associated with the tuned Stacking Classifier using roc_auc metric is:  0.8004241337179158\n"
     ]
    }
   ],
   "source": [
    "print('The reward associated with the tuned Stacking Classifier using roc_auc metric is: ',np.mean(score_Stacking))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The risk associated with the tuned Stacking Classifier  using roc_auc metric is:  0.016554226064379108\n"
     ]
    }
   ],
   "source": [
    "print('The risk associated with the tuned Stacking Classifier  using roc_auc metric is: ',np.std(score_Stacking))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_R_Ratio_Stacking = np.mean(score_Stacking)/np.std(score_Stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reward risk ratio for the tuned Stacking Classifier using roc_auc metric is:  48.351649337461005\n"
     ]
    }
   ],
   "source": [
    "print('The reward risk ratio for the tuned Stacking Classifier using roc_auc metric is: ',R_R_Ratio_Stacking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations: \n",
    "### 1) The test set roc_auc score for the Stacking classifier is more than that of  Neural Net classifier , but less than that of the Voting classifier , both of which were used to create the training  as well as test set for the stacking classifier.\n",
    "### 2) Similarly the R_R ratio of the Stacking classifier is approx. equal (although more) to that of the Voting Classifier, but much less than that of the Neural Net. Thus, even with added complexity, the Stacking Classifier still hasn't been able to beat the tuned Random Forest Classifier on this dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  The R_R Ratio for the tuned Stacking Classifier using roc_auc metric is:  48.351649337461005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
