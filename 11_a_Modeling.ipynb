{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Required Python Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Reduced feature Training set\n",
    "X_train_red = pd.read_csv('X_train_final.csv')\n",
    "y_train = pd.read_csv('y_train.final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Reduced feature Test set\n",
    "X_test_red = pd.read_csv('X_test_final.csv')\n",
    "y_test = pd.read_csv('y_test.final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading all the best models from various categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Joblib module\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing best Logistic regression Classifier\n",
    "lr = joblib.load('Log_Reg_Reduced.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing best Random Forest Classifier\n",
    "rf = joblib.load('Rand_Forest_Reduced.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing best Light Gbm Classifier\n",
    "lgbm = joblib.load('Light_Gbm_Reduced.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing best Neural Net Classifier\n",
    "neural = keras.models.load_model('Best_model_Selu_eq_Learn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing best Linear Discriminant Analysis Classifier\n",
    "lda = joblib.load('Linear_Dis_Reduced.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model_13: Voting Classifier with Default Parameters & Soft_Voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Voting classifier from sklearn\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Sklearn's roc_auc_score module\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(estimators=[('logistic_Reg',lr),('Random_Forest',rf),('Light_Gbm',lgbm),\n",
    "                                           ('Linear_Dis',lda)],voting='soft',n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('logistic_Reg',\n",
       "                              LogisticRegression(C=0.12725888493400458,\n",
       "                                                 class_weight={0: 1.0, 1: 9.0},\n",
       "                                                 l1_ratio=0.9851193622801032,\n",
       "                                                 n_jobs=5, penalty='elasticnet',\n",
       "                                                 random_state=42,\n",
       "                                                 solver='saga')),\n",
       "                             ('Random_Forest',\n",
       "                              RandomForestClassifier(class_weight='balanced',\n",
       "                                                     max_depth=11,\n",
       "                                                     min_samples_leaf=0.000264150675671259,\n",
       "                                                     n_estimators=1560,\n",
       "                                                     n_jobs=5,\n",
       "                                                     rando...\n",
       "                                             colsample_bytree=0.6688983257726496,\n",
       "                                             learning_rate=0.0030081514412958507,\n",
       "                                             max_depth=85, min_child_samples=16,\n",
       "                                             n_estimators=1083, n_jobs=5,\n",
       "                                             num_leaves=26, objective='binary',\n",
       "                                             random_state=42,\n",
       "                                             reg_alpha=6.964534534541776,\n",
       "                                             reg_lambda=5.143496762382144)),\n",
       "                             ('Linear_Dis',\n",
       "                              LinearDiscriminantAnalysis(shrinkage=0.0023665526949698365,\n",
       "                                                         solver='eigen'))],\n",
       "                 n_jobs=5, voting='soft')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the vanilla voting classifier on the Reduced Feature Training set\n",
    "voting_clf.fit(X_train_red, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the function to calculate the roc_auc score for the feature sets\n",
    "def cal_roc_auc(X, y, cls, f_set, t_set, model_name):\n",
    "    ''' Calculates the roc auc score using the best study parameters \n",
    "        f_set : String: specifies 'full feature', 'Reduced feature'\n",
    "        t_set: String: specifies 'training', 'test'\n",
    "        model_name: String: specifies Name of the model '''\n",
    "        \n",
    "    y_pred = cls.predict_proba(X)\n",
    "    print('The roc_auc_score for the {} {} set using the {} is '.format(f_set,t_set,model_name),roc_auc_score(y,y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The roc_auc_score for the reduced feature training set using the  default Voting Classifier is  0.8261782556386233\n"
     ]
    }
   ],
   "source": [
    "# Calculating the reduced feature training set roc_auc score using the best study parameters\n",
    "cal_roc_auc(X_train_red, y_train, voting_clf,'reduced feature','training',' default Voting Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The roc_auc_score for the reduced feature test set using the default Voting Classifier is  0.8114581613519506\n"
     ]
    }
   ],
   "source": [
    "# Calculating the reduced feature test roc_auc score using the best study parameters\n",
    "cal_roc_auc(X_test_red, y_test, voting_clf,'reduced feature','test','default Voting Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Voting_Red_default.joblib']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the default voting Classifier\n",
    "import joblib\n",
    "joblib.dump(voting_clf,'Voting_Red_default.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating R_R ratio for default Voting Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required Libraries\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the Stratified K fold object\n",
    "cv_strat = StratifiedKFold(10,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the CV scores using sklearn's cross_val_score\n",
    "score_voting_default = cross_val_score(voting_clf, X_train_red, y_train, cv=cv_strat, n_jobs=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reward associated with the default Voting Classifier using roc_auc metric is:  0.7994986354233928\n"
     ]
    }
   ],
   "source": [
    "print('The reward associated with the default Voting Classifier using roc_auc metric is: ',np.mean(score_voting_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The risk associated with the default Voting Classifier using roc_auc metric is:  0.016226315881551476\n"
     ]
    }
   ],
   "source": [
    "print('The risk associated with the default Voting Classifier using roc_auc metric is: ',np.std(score_voting_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_R_Ratio_voting_default = np.mean(score_voting_default)/np.std(score_voting_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reward risk ratio for the default Voting Classifier using roc_auc metric is:  49.271728792879195\n"
     ]
    }
   ],
   "source": [
    "print('The reward risk ratio for the default Voting Classifier using roc_auc metric is: ',R_R_Ratio_voting_default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R_R Ratio for the default Voting classifier using reduced feature set is: 49.271728792879195"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations: \n",
    "### 1) The test set roc_auc score for the default voting classifier is more than that of component Logistic Regression & LDA, but less than that of  Random Forest & LightGBM. May be changing the weights of voting classifier result in better results.\n",
    "### 2) On the other hand, the R_R ratio for the default voting classifier model is more than that of Logistic regression & LightGBM , but less than that of Random forest & LDA. So clearly Random Forest bests  default Voting classifier hands down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model_13: Voting Classifier with Tuned weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a new voting classifier object\n",
    "voting_clf_2 = VotingClassifier(estimators=[('logistic_Reg',lr),('Random_Forest',rf),('Light_Gbm',lgbm),\n",
    "                                           ('Linear_Dis',lda)],voting='soft',n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the appropriate objective function for the best weights of Voting classifier.\n",
    "def objective_wrappper_Vt_2(X_tr, y_tr, cls=None, cv_strat=None):\n",
    "    '''\n",
    "    Optimizes voting classifier (cls) weights parameter on the given training set X_tr,y_tr\n",
    "      \n",
    "    '''\n",
    "    \n",
    "    def objective(trial):\n",
    "        w1 = trial.suggest_uniform('w1',-1,1)\n",
    "        w2 = trial.suggest_uniform('w2',-1,1)\n",
    "        w3 = trial.suggest_uniform('w3',-1,1)\n",
    "        w4 = trial.suggest_uniform('w4',-1,1)\n",
    "        \n",
    "        params = {\n",
    "            'weights':[w1,w2,w3,w4]                 \n",
    "            }\n",
    "        \n",
    "        cls.set_params(**params)#Initializing the model with the parameter\n",
    "               \n",
    "        return np.mean(cross_val_score(cls, X_tr, y_tr, cv=cv_strat, n_jobs=5, scoring='roc_auc'))\n",
    "    \n",
    "    return objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the best weights for the Voting Classifier_2 using Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the evaluation function for study's best parameters\n",
    "def train_test_roc_auc(X_tr, y_tr, cls, obj_func, cv_strat, n_trials=100):\n",
    "    ''' Computes the best hyper parameters of the classsifier and returns \n",
    "    Optuna's study's best score & clasifier parameters'''\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(obj_func(X_tr, y_tr, cls, cv_strat), n_trials)\n",
    "    best_score = study.best_value\n",
    "    best_params = study.best_params\n",
    "    return (best_score,best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-09 01:49:51,417] A new study created in memory with name: no-name-10a255f2-6cbe-4a24-bd10-cd52b8d43b20\n",
      "[I 2020-10-09 01:51:17,556] Trial 0 finished with value: 0.5829850701192909 and parameters: {'w1': 0.1038898457697357, 'w2': -0.7058492808036847, 'w3': 0.025250530887687583, 'w4': 0.44266115384040594}. Best is trial 0 with value: 0.5829850701192909.\n",
      "[I 2020-10-09 01:53:01,586] Trial 1 finished with value: 0.5837460812121741 and parameters: {'w1': -0.9867733185292686, 'w2': 0.7856035983802627, 'w3': 0.83641583303722, 'w4': -0.7831608968403647}. Best is trial 1 with value: 0.5837460812121741.\n",
      "[I 2020-10-09 01:54:49,553] Trial 2 finished with value: 0.7756791747079623 and parameters: {'w1': 0.3885807116486186, 'w2': 0.9994103258417006, 'w3': 0.05856411622978519, 'w4': -0.6883430815552989}. Best is trial 2 with value: 0.7756791747079623.\n",
      "[I 2020-10-09 01:56:33,147] Trial 3 finished with value: 0.7946751883433738 and parameters: {'w1': -0.8966206571876429, 'w2': 0.30782819131362005, 'w3': -0.49164394947343504, 'w4': -0.3790618694521153}. Best is trial 3 with value: 0.7946751883433738.\n",
      "[I 2020-10-09 01:58:17,979] Trial 4 finished with value: 0.7983688991193871 and parameters: {'w1': 0.0789045019910064, 'w2': 0.7110935798781297, 'w3': -0.18204959232857076, 'w4': 0.07827423638741826}. Best is trial 4 with value: 0.7983688991193871.\n",
      "[I 2020-10-09 02:00:06,351] Trial 5 finished with value: 0.732564619038655 and parameters: {'w1': 0.7488819762850965, 'w2': -0.46226451486845344, 'w3': -0.827736298218662, 'w4': 0.2351954914085701}. Best is trial 4 with value: 0.7983688991193871.\n",
      "[I 2020-10-09 02:01:51,694] Trial 6 finished with value: 0.5104261203937882 and parameters: {'w1': -0.0091912019831768, 'w2': 0.3772722290869359, 'w3': -0.07192814970655315, 'w4': -0.2646880294027729}. Best is trial 4 with value: 0.7983688991193871.\n",
      "[I 2020-10-09 02:03:36,711] Trial 7 finished with value: 0.6862627258845789 and parameters: {'w1': 0.7396374942452393, 'w2': 0.31649540849204594, 'w3': -0.609066129188625, 'w4': -0.994388252844782}. Best is trial 4 with value: 0.7983688991193871.\n",
      "[I 2020-10-09 02:05:33,069] Trial 8 finished with value: 0.7811512007348084 and parameters: {'w1': 0.37364255996691, 'w2': 0.8225093112261825, 'w3': -0.7628794288098777, 'w4': 0.42575878325095173}. Best is trial 4 with value: 0.7983688991193871.\n",
      "[I 2020-10-09 02:07:20,664] Trial 9 finished with value: 0.7558435526535823 and parameters: {'w1': 0.22102114270747708, 'w2': 0.9656736022504406, 'w3': -0.9660826273695475, 'w4': 0.12341781447302003}. Best is trial 4 with value: 0.7983688991193871.\n",
      "[I 2020-10-09 02:09:01,758] Trial 10 finished with value: 0.7751810334790167 and parameters: {'w1': -0.42931584166001685, 'w2': -0.20413032406407908, 'w3': 0.5912615824447631, 'w4': 0.9840630304270974}. Best is trial 4 with value: 0.7983688991193871.\n",
      "[I 2020-10-09 02:10:49,882] Trial 11 finished with value: 0.7910231922919325 and parameters: {'w1': -0.46490173604295826, 'w2': 0.423794303176836, 'w3': -0.37666119809376203, 'w4': -0.29884439789612477}. Best is trial 4 with value: 0.7983688991193871.\n",
      "[I 2020-10-09 02:12:36,055] Trial 12 finished with value: 0.7955557858386266 and parameters: {'w1': -0.940728812693112, 'w2': 0.08019445805846556, 'w3': -0.3799558460704403, 'w4': -0.2926476579528011}. Best is trial 4 with value: 0.7983688991193871.\n",
      "[I 2020-10-09 02:14:20,164] Trial 13 finished with value: 0.798884005876437 and parameters: {'w1': -0.2911958747361264, 'w2': -0.08095467576692165, 'w3': -0.21729939736616585, 'w4': -0.05922643594343393}. Best is trial 13 with value: 0.798884005876437.\n",
      "[I 2020-10-09 02:16:08,836] Trial 14 finished with value: 0.7153114019015409 and parameters: {'w1': -0.28132925269146924, 'w2': -0.1843659334586355, 'w3': 0.2882381018322251, 'w4': 0.6626286101378106}. Best is trial 13 with value: 0.798884005876437.\n",
      "[I 2020-10-09 02:17:56,602] Trial 15 finished with value: 0.7989862393024616 and parameters: {'w1': -0.18141573759657198, 'w2': 0.014171686440672585, 'w3': -0.20407300329883554, 'w4': -0.034748493006332454}. Best is trial 15 with value: 0.7989862393024616.\n",
      "[I 2020-10-09 02:19:49,429] Trial 16 finished with value: 0.7965918333085422 and parameters: {'w1': -0.614894835706189, 'w2': -0.9056417479401337, 'w3': 0.3184372242129699, 'w4': -0.05734132620668201}. Best is trial 15 with value: 0.7989862393024616.\n",
      "[I 2020-10-09 02:21:37,353] Trial 17 finished with value: 0.797809644051517 and parameters: {'w1': -0.21072168574665368, 'w2': 0.01212700464751149, 'w3': -0.23843344830663163, 'w4': -0.6134636009131943}. Best is trial 15 with value: 0.7989862393024616.\n",
      "[I 2020-10-09 02:23:24,288] Trial 18 finished with value: 0.7928433895841657 and parameters: {'w1': -0.6010235046808731, 'w2': -0.32931879677367154, 'w3': 0.19341413534098598, 'w4': -0.060902467832255856}. Best is trial 15 with value: 0.7989862393024616.\n",
      "[I 2020-10-09 02:25:09,008] Trial 19 finished with value: 0.7079823924216677 and parameters: {'w1': -0.12939045057031184, 'w2': -0.5787823234355949, 'w3': 0.5786594567672595, 'w4': 0.3909039050129946}. Best is trial 15 with value: 0.7989862393024616.\n",
      "[I 2020-10-09 02:26:56,226] Trial 20 finished with value: 0.7017280713075796 and parameters: {'w1': -0.7085066752059155, 'w2': 0.1420558537416477, 'w3': -0.6206817919312029, 'w4': 0.6945056403505858}. Best is trial 15 with value: 0.7989862393024616.\n",
      "[I 2020-10-09 02:28:44,197] Trial 21 finished with value: 0.7965093037558648 and parameters: {'w1': -0.06606381321265853, 'w2': 0.5723235150352162, 'w3': -0.16665130431913594, 'w4': 0.07124457885227348}. Best is trial 15 with value: 0.7989862393024616.\n",
      "[I 2020-10-09 02:30:34,958] Trial 22 finished with value: 0.7994239141358777 and parameters: {'w1': -0.3281079934754995, 'w2': -0.1423990227944908, 'w3': -0.2794930774311284, 'w4': -0.05176002751686297}. Best is trial 22 with value: 0.7994239141358777.\n",
      "[I 2020-10-09 02:32:32,532] Trial 23 finished with value: 0.7990865668550337 and parameters: {'w1': -0.35190767509893534, 'w2': -0.12347843775545558, 'w3': -0.3110918172016065, 'w4': -0.15020468758030353}. Best is trial 22 with value: 0.7994239141358777.\n",
      "[I 2020-10-09 02:34:23,981] Trial 24 finished with value: 0.7990626593208386 and parameters: {'w1': -0.4204266063569901, 'w2': -0.31862130183771625, 'w3': -0.3696671954618005, 'w4': -0.44038591976387503}. Best is trial 22 with value: 0.7994239141358777.\n",
      "[I 2020-10-09 02:36:13,188] Trial 25 finished with value: 0.7992586829278752 and parameters: {'w1': -0.42815888023158116, 'w2': -0.33414808652019734, 'w3': -0.416682649450841, 'w4': -0.4349132246110112}. Best is trial 22 with value: 0.7994239141358777.\n",
      "[I 2020-10-09 02:38:01,874] Trial 26 finished with value: 0.799466848470537 and parameters: {'w1': -0.6975947391068344, 'w2': -0.7364537091789519, 'w3': -0.5740886605829703, 'w4': -0.5199304546847082}. Best is trial 26 with value: 0.799466848470537.\n",
      "[I 2020-10-09 02:39:51,755] Trial 27 finished with value: 0.7994550830883176 and parameters: {'w1': -0.7777047131927068, 'w2': -0.8780621129855808, 'w3': -0.5594155090497894, 'w4': -0.49582365096885395}. Best is trial 26 with value: 0.799466848470537.\n",
      "[I 2020-10-09 02:41:44,256] Trial 28 finished with value: 0.7991852904727936 and parameters: {'w1': -0.7654202369885847, 'w2': -0.9698858828661876, 'w3': -0.5863399973438339, 'w4': -0.9756815476438363}. Best is trial 26 with value: 0.799466848470537.\n",
      "[I 2020-10-09 02:43:28,491] Trial 29 finished with value: 0.7997343449080679 and parameters: {'w1': -0.8067508922873381, 'w2': -0.8349874957075268, 'w3': -0.9667287739181569, 'w4': -0.8311897910291581}. Best is trial 29 with value: 0.7997343449080679.\n",
      "[I 2020-10-09 02:45:22,010] Trial 30 finished with value: 0.7996460896263029 and parameters: {'w1': -0.8213909102092931, 'w2': -0.743646063403171, 'w3': -0.9972235580008793, 'w4': -0.8634243958081662}. Best is trial 29 with value: 0.7997343449080679.\n",
      "[I 2020-10-09 02:47:09,217] Trial 31 finished with value: 0.7996177631884167 and parameters: {'w1': -0.8470740323401207, 'w2': -0.775356151391586, 'w3': -0.972485293801724, 'w4': -0.8419802745407683}. Best is trial 29 with value: 0.7997343449080679.\n",
      "[I 2020-10-09 02:48:55,913] Trial 32 finished with value: 0.7994189185028074 and parameters: {'w1': -0.9807834477050992, 'w2': -0.7582901526481898, 'w3': -0.9848975911163576, 'w4': -0.842508838195074}. Best is trial 29 with value: 0.7997343449080679.\n",
      "[I 2020-10-09 02:50:43,897] Trial 33 finished with value: 0.7993747020328046 and parameters: {'w1': -0.869586060598335, 'w2': -0.7027328977397808, 'w3': -0.8657693705214653, 'w4': -0.8254961252643154}. Best is trial 29 with value: 0.7997343449080679.\n",
      "[I 2020-10-09 02:52:28,462] Trial 34 finished with value: 0.7996424075339683 and parameters: {'w1': -0.6653437962337813, 'w2': -0.7514988242650598, 'w3': -0.7148640959046884, 'w4': -0.7014683673377953}. Best is trial 29 with value: 0.7997343449080679.\n",
      "[I 2020-10-09 02:54:16,461] Trial 35 finished with value: 0.7997300724735754 and parameters: {'w1': -0.5864990300815007, 'w2': -0.5905177569659865, 'w3': -0.7688851659238362, 'w4': -0.7038981548801149}. Best is trial 29 with value: 0.7997343449080679.\n",
      "[I 2020-10-09 02:56:03,437] Trial 36 finished with value: 0.7996005140002259 and parameters: {'w1': -0.5806966143978706, 'w2': -0.5380463007745, 'w3': -0.7351842438253412, 'w4': -0.7185876125143924}. Best is trial 29 with value: 0.7997343449080679.\n",
      "[I 2020-10-09 02:57:54,577] Trial 37 finished with value: 0.7995233102916407 and parameters: {'w1': -0.9897224676907271, 'w2': -0.9959173257649706, 'w3': -0.8231602968775171, 'w4': -0.6384174811092465}. Best is trial 29 with value: 0.7997343449080679.\n",
      "[I 2020-10-09 02:59:40,360] Trial 38 finished with value: 0.799481565606951 and parameters: {'w1': -0.5559444426120975, 'w2': -0.6013837072427353, 'w3': -0.7136023863071829, 'w4': -0.9348548746984753}. Best is trial 29 with value: 0.7997343449080679.\n",
      "[I 2020-10-09 03:01:33,836] Trial 39 finished with value: 0.7992813256520506 and parameters: {'w1': -0.8680637040028403, 'w2': -0.43038337551408956, 'w3': -0.8810207361362211, 'w4': -0.5876688164994573}. Best is trial 29 with value: 0.7997343449080679.\n",
      "[I 2020-10-09 03:03:25,394] Trial 40 finished with value: 0.8000177627658133 and parameters: {'w1': -0.7025762127605901, 'w2': -0.8558560317839969, 'w3': -0.9922992143020513, 'w4': -0.7445289235476564}. Best is trial 40 with value: 0.8000177627658133.\n",
      "[I 2020-10-09 03:05:12,943] Trial 41 finished with value: 0.8000790260845297 and parameters: {'w1': -0.698666381332957, 'w2': -0.8754747802988996, 'w3': -0.9903062449129895, 'w4': -0.6949832557626275}. Best is trial 41 with value: 0.8000790260845297.\n",
      "[I 2020-10-09 03:07:05,770] Trial 42 finished with value: 0.7998322304452052 and parameters: {'w1': -0.7715542053977014, 'w2': -0.9410970308423146, 'w3': -0.9860274292600779, 'w4': -0.8995421622792485}. Best is trial 41 with value: 0.8000790260845297.\n",
      "[I 2020-10-09 03:08:56,640] Trial 43 finished with value: 0.800049084478907 and parameters: {'w1': -0.5208736505015841, 'w2': -0.8952672219315181, 'w3': -0.9065613816413222, 'w4': -0.9396600229519496}. Best is trial 41 with value: 0.8000790260845297.\n",
      "[I 2020-10-09 03:10:43,248] Trial 44 finished with value: 0.8000049617059076 and parameters: {'w1': -0.509999601827969, 'w2': -0.8746268893139104, 'w3': -0.8965639980506084, 'w4': -0.9919071365996751}. Best is trial 41 with value: 0.8000790260845297.\n",
      "[I 2020-10-09 03:12:35,321] Trial 45 finished with value: 0.7957644543097592 and parameters: {'w1': 0.9604302221639006, 'w2': -0.9897026411425726, 'w3': -0.8996243028738382, 'w4': -0.9912816583479922}. Best is trial 41 with value: 0.8000790260845297.\n",
      "[I 2020-10-09 03:14:28,350] Trial 46 finished with value: 0.8000954421335672 and parameters: {'w1': -0.4887989471215046, 'w2': -0.9094893517554312, 'w3': -0.8873888114242121, 'w4': -0.9233202637534624}. Best is trial 46 with value: 0.8000954421335672.\n",
      "[I 2020-10-09 03:16:15,605] Trial 47 finished with value: 0.7998848765993253 and parameters: {'w1': -0.4866485313689567, 'w2': -0.6586423358563664, 'w3': -0.8962367373411989, 'w4': -0.9960970484659464}. Best is trial 46 with value: 0.8000954421335672.\n",
      "[I 2020-10-09 03:18:08,801] Trial 48 finished with value: 0.8005307064349353 and parameters: {'w1': 0.13402500351880287, 'w2': -0.8556871410384933, 'w3': -0.6512699587460842, 'w4': -0.7215385215222777}. Best is trial 48 with value: 0.8005307064349353.\n",
      "[I 2020-10-09 03:19:55,367] Trial 49 finished with value: 0.8003109613550196 and parameters: {'w1': 0.2225601950238266, 'w2': -0.822677619260236, 'w3': -0.6534780919791852, 'w4': -0.7914891785226311}. Best is trial 48 with value: 0.8005307064349353.\n",
      "[I 2020-10-09 03:21:43,088] Trial 50 finished with value: 0.8005173063615627 and parameters: {'w1': 0.133286386275076, 'w2': -0.4784933821039375, 'w3': -0.6827075953710616, 'w4': -0.5683683036529086}. Best is trial 48 with value: 0.8005307064349353.\n",
      "[I 2020-10-09 03:23:35,495] Trial 51 finished with value: 0.8001287228904204 and parameters: {'w1': 0.16991913798213282, 'w2': -0.44716520331805015, 'w3': -0.4607612680362297, 'w4': -0.5442805915130817}. Best is trial 48 with value: 0.8005307064349353.\n",
      "[I 2020-10-09 03:25:25,231] Trial 52 finished with value: 0.8002318273169126 and parameters: {'w1': 0.20374831158283552, 'w2': -0.43264056072197526, 'w3': -0.47814585279413746, 'w4': -0.3455604830003713}. Best is trial 48 with value: 0.8005307064349353.\n",
      "[I 2020-10-09 03:27:09,241] Trial 53 finished with value: 0.8004748086565335 and parameters: {'w1': 0.20283389637637625, 'w2': -0.4719397234961363, 'w3': -0.4938937905749191, 'w4': -0.21996292500274905}. Best is trial 48 with value: 0.8005307064349353.\n",
      "[I 2020-10-09 03:28:56,320] Trial 54 finished with value: 0.8005086496221434 and parameters: {'w1': 0.19098715037780412, 'w2': -0.46945185104889975, 'w3': -0.4588860196180414, 'w4': -0.18513254281980798}. Best is trial 48 with value: 0.8005307064349353.\n",
      "[I 2020-10-09 03:30:43,882] Trial 55 finished with value: 0.7962653983238029 and parameters: {'w1': 0.34642694768311655, 'w2': -0.2526420863352873, 'w3': -0.4839293615423374, 'w4': -0.17759699229542142}. Best is trial 48 with value: 0.8005307064349353.\n",
      "[I 2020-10-09 03:32:31,696] Trial 56 finished with value: 0.7709433695574343 and parameters: {'w1': 0.5130818647172566, 'w2': -0.5075568961782302, 'w3': -0.06373738700835896, 'w4': -0.35846775915043944}. Best is trial 48 with value: 0.8005307064349353.\n",
      "[I 2020-10-09 03:34:19,942] Trial 57 finished with value: 0.8010531170667854 and parameters: {'w1': 0.060991318559487334, 'w2': -0.4046081494931331, 'w3': -0.644687862002245, 'w4': -0.22326257963250062}. Best is trial 57 with value: 0.8010531170667854.\n",
      "[I 2020-10-09 03:36:09,359] Trial 58 finished with value: 0.8011056963859364 and parameters: {'w1': 0.061974533040258045, 'w2': -0.3702656446841187, 'w3': -0.6551993933271569, 'w4': -0.18340785415290606}. Best is trial 58 with value: 0.8011056963859364.\n",
      "[I 2020-10-09 03:37:54,560] Trial 59 finished with value: 0.8010558249941162 and parameters: {'w1': 0.016660272577378246, 'w2': -0.3725417820764009, 'w3': -0.6633200981573675, 'w4': -0.23048616734347652}. Best is trial 58 with value: 0.8011056963859364.\n",
      "[I 2020-10-09 03:39:42,711] Trial 60 finished with value: 0.793483281581534 and parameters: {'w1': 0.0690587081736993, 'w2': -0.2662556321224825, 'w3': -0.6299242793049644, 'w4': 0.17625235198124606}. Best is trial 58 with value: 0.8011056963859364.\n",
      "[I 2020-10-09 03:41:31,507] Trial 61 finished with value: 0.8011006826313187 and parameters: {'w1': -0.001870558508585824, 'w2': -0.3706045654432657, 'w3': -0.6873280869130651, 'w4': -0.21377628825474893}. Best is trial 58 with value: 0.8011056963859364.\n",
      "[I 2020-10-09 03:43:17,759] Trial 62 finished with value: 0.8009182790222115 and parameters: {'w1': -0.04803790221108972, 'w2': -0.05651046012087968, 'w3': -0.680477604916642, 'w4': -0.1267159734965626}. Best is trial 58 with value: 0.8011056963859364.\n",
      "[I 2020-10-09 03:45:07,055] Trial 63 finished with value: 0.8012767991170631 and parameters: {'w1': 0.035924773031578164, 'w2': -0.3919943001519822, 'w3': -0.7798371739865604, 'w4': 0.020692089220053944}. Best is trial 63 with value: 0.8012767991170631.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-09 03:46:50,759] Trial 64 finished with value: 0.798709979378647 and parameters: {'w1': -0.054264392642794035, 'w2': 0.19769572490578338, 'w3': -0.797129249461288, 'w4': 0.05141668280484202}. Best is trial 63 with value: 0.8012767991170631.\n",
      "[I 2020-10-09 03:48:36,429] Trial 65 finished with value: 0.8007373172496075 and parameters: {'w1': 0.036728486130442856, 'w2': -0.03133266363989179, 'w3': -0.5590136259925164, 'w4': -0.1146057982520279}. Best is trial 63 with value: 0.8012767991170631.\n",
      "[I 2020-10-09 03:50:26,775] Trial 66 finished with value: 0.8008098060871992 and parameters: {'w1': 0.01957174872373488, 'w2': -0.0592196571212438, 'w3': -0.5494146015229269, 'w4': -0.1406341471614976}. Best is trial 63 with value: 0.8012767991170631.\n",
      "[I 2020-10-09 03:52:15,135] Trial 67 finished with value: 0.7905679995462143 and parameters: {'w1': -0.00491412504663756, 'w2': -0.3675543414259161, 'w3': -0.794107026625973, 'w4': 0.30558130111505255}. Best is trial 63 with value: 0.8012767991170631.\n",
      "[I 2020-10-09 03:54:00,273] Trial 68 finished with value: 0.8005923631477975 and parameters: {'w1': -0.13815266293541134, 'w2': -0.19036478099593704, 'w3': -0.5541429952942466, 'w4': -0.2679991993280773}. Best is trial 63 with value: 0.8012767991170631.\n",
      "[I 2020-10-09 03:55:46,602] Trial 69 finished with value: 0.793378063455698 and parameters: {'w1': 0.3202533455087438, 'w2': -0.07015800257303029, 'w3': -0.7459423871749811, 'w4': 0.010013439177752353}. Best is trial 63 with value: 0.8012767991170631.\n",
      "[I 2020-10-09 03:57:34,723] Trial 70 finished with value: 0.8005749797270898 and parameters: {'w1': -0.2227230386755258, 'w2': -0.37953598657059007, 'w3': -0.3537296094382991, 'w4': -0.12331597060083999}. Best is trial 63 with value: 0.8012767991170631.\n",
      "[I 2020-10-09 03:59:21,594] Trial 71 finished with value: 0.7995191780698196 and parameters: {'w1': 0.053447116699134156, 'w2': 0.08498392018853407, 'w3': -0.5610884504185351, 'w4': -0.13201318311012863}. Best is trial 63 with value: 0.8012767991170631.\n",
      "[I 2020-10-09 04:01:15,157] Trial 72 finished with value: 0.7982984087708387 and parameters: {'w1': -0.06851405015961821, 'w2': -0.042635876175340426, 'w3': -0.66948413626851, 'w4': 0.12405823352547687}. Best is trial 63 with value: 0.8012767991170631.\n",
      "[I 2020-10-09 04:03:06,460] Trial 73 finished with value: 0.801203192639585 and parameters: {'w1': 0.035978958658934815, 'w2': -0.2604745727749048, 'w3': -0.5390438595419457, 'w4': -0.10075239603697358}. Best is trial 63 with value: 0.8012767991170631.\n",
      "[I 2020-10-09 04:04:54,341] Trial 74 finished with value: 0.7987713107351457 and parameters: {'w1': 0.2821417304317427, 'w2': -0.26663756633275487, 'w3': -0.5288737535934022, 'w4': -0.23367791905470667}. Best is trial 63 with value: 0.8012767991170631.\n",
      "[I 2020-10-09 04:06:46,626] Trial 75 finished with value: 0.7946717409311657 and parameters: {'w1': 0.4298366944269454, 'w2': -0.1976794885196743, 'w3': -0.6098550470586132, 'w4': -0.31702701503134006}. Best is trial 63 with value: 0.8012767991170631.\n",
      "[I 2020-10-09 04:08:39,879] Trial 76 finished with value: 0.8005252520180248 and parameters: {'w1': -0.09285128911786777, 'w2': -0.15432019699149446, 'w3': -0.8271769625425505, 'w4': -0.41309233327858497}. Best is trial 63 with value: 0.8012767991170631.\n",
      "[I 2020-10-09 04:10:29,227] Trial 77 finished with value: 0.8014569106242455 and parameters: {'w1': -0.01892659811471946, 'w2': -0.12205104743904709, 'w3': -0.4097477051900742, 'w4': -0.007396756446858069}. Best is trial 77 with value: 0.8014569106242455.\n",
      "[I 2020-10-09 04:12:20,204] Trial 78 finished with value: 0.8009805414292908 and parameters: {'w1': -0.1637202573205564, 'w2': -0.2803933096855379, 'w3': -0.29389969708543956, 'w4': -0.0008883687765274262}. Best is trial 77 with value: 0.8014569106242455.\n",
      "[I 2020-10-09 04:14:13,806] Trial 79 finished with value: 0.8009834529769062 and parameters: {'w1': -0.16451873182035043, 'w2': -0.30890234311460524, 'w3': -0.2868358885297941, 'w4': 0.002443944825168562}. Best is trial 77 with value: 0.8014569106242455.\n",
      "[I 2020-10-09 04:16:02,338] Trial 80 finished with value: 0.7988746599054475 and parameters: {'w1': -0.26006368276510883, 'w2': -0.3760803066817241, 'w3': -0.15899302672155713, 'w4': 0.1460965250993645}. Best is trial 77 with value: 0.8014569106242455.\n",
      "[I 2020-10-09 04:17:55,379] Trial 81 finished with value: 0.8008916341801022 and parameters: {'w1': -0.18522691055972315, 'w2': -0.3042672305953842, 'w3': -0.2855694843245235, 'w4': 0.005921986744593724}. Best is trial 77 with value: 0.8014569106242455.\n",
      "[I 2020-10-09 04:19:42,766] Trial 82 finished with value: 0.8010076819904525 and parameters: {'w1': -0.1482741251420936, 'w2': -0.23089823400644235, 'w3': -0.41050087915830946, 'w4': -0.07340473977408032}. Best is trial 77 with value: 0.8014569106242455.\n",
      "[I 2020-10-09 04:21:31,748] Trial 83 finished with value: 0.8011844288258783 and parameters: {'w1': -0.11454284711034807, 'w2': -0.226551497830138, 'w3': -0.4209907731301783, 'w4': -0.05980852496601884}. Best is trial 77 with value: 0.8014569106242455.\n",
      "[I 2020-10-09 04:23:25,937] Trial 84 finished with value: 0.6999571145294954 and parameters: {'w1': 0.0972388698597866, 'w2': -0.1123455434129706, 'w3': -0.37716922965501665, 'w4': 0.22383459073499562}. Best is trial 77 with value: 0.8014569106242455.\n",
      "[I 2020-10-09 04:25:16,736] Trial 85 finished with value: 0.8011589550537185 and parameters: {'w1': -0.09877845066587296, 'w2': -0.21922305910791348, 'w3': -0.4030964324965344, 'w4': -0.07859483537081441}. Best is trial 77 with value: 0.8014569106242455.\n",
      "[I 2020-10-09 04:27:04,317] Trial 86 finished with value: 0.8009728893083936 and parameters: {'w1': -0.016825795117231875, 'w2': -0.39608565928043044, 'w3': -0.4213479323393936, 'w4': -0.21850879034883758}. Best is trial 77 with value: 0.8014569106242455.\n",
      "[I 2020-10-09 04:28:55,530] Trial 87 finished with value: 0.7979778741173942 and parameters: {'w1': -0.10365543161836864, 'w2': -0.528890169560874, 'w3': 0.10558284800711282, 'w4': 0.07723002771878126}. Best is trial 77 with value: 0.8014569106242455.\n",
      "[I 2020-10-09 04:30:48,899] Trial 88 finished with value: 0.800052331525581 and parameters: {'w1': 0.11751048410235035, 'w2': -0.13967889541063033, 'w3': 0.9668598912076675, 'w4': -0.0820824377566654}. Best is trial 77 with value: 0.8014569106242455.\n",
      "[I 2020-10-09 04:32:47,963] Trial 89 finished with value: 0.799309379652941 and parameters: {'w1': -0.3222530539575708, 'w2': -0.1972769842861141, 'w3': -0.3384705527483797, 'w4': -0.28300961520994855}. Best is trial 77 with value: 0.8014569106242455.\n",
      "[I 2020-10-09 04:34:40,398] Trial 90 finished with value: 0.8011318524491602 and parameters: {'w1': -0.011448204075884984, 'w2': -0.3420726693890857, 'w3': -0.7085991308178828, 'w4': -0.19036534950622566}. Best is trial 77 with value: 0.8014569106242455.\n",
      "[I 2020-10-09 04:36:33,145] Trial 91 finished with value: 0.8012085085403768 and parameters: {'w1': -0.030768369859755937, 'w2': -0.3824355654872966, 'w3': -0.7171597453041018, 'w4': -0.17943578399937696}. Best is trial 77 with value: 0.8014569106242455.\n",
      "[I 2020-10-09 04:38:20,435] Trial 92 finished with value: 0.8011411845218428 and parameters: {'w1': -0.010615016726298526, 'w2': -0.32026101881243185, 'w3': -0.7206710184596355, 'w4': -0.1810394502804157}. Best is trial 77 with value: 0.8014569106242455.\n",
      "[I 2020-10-09 04:40:12,683] Trial 93 finished with value: 0.8012780003200746 and parameters: {'w1': -0.03563147987572737, 'w2': -0.33507095143075954, 'w3': -0.7171929612093934, 'w4': 0.05551882965022272}. Best is trial 77 with value: 0.8014569106242455.\n",
      "[I 2020-10-09 04:42:00,049] Trial 94 finished with value: 0.8012355654777131 and parameters: {'w1': -0.25310793536122755, 'w2': -0.32509255256588887, 'w3': -0.7811379132222294, 'w4': -0.02175838288405324}. Best is trial 77 with value: 0.8014569106242455.\n",
      "[I 2020-10-09 04:43:52,875] Trial 95 finished with value: 0.8013547243971899 and parameters: {'w1': -0.24073048803159985, 'w2': -0.23178799841018374, 'w3': -0.7581182351706199, 'w4': 0.06598624010363445}. Best is trial 77 with value: 0.8014569106242455.\n",
      "[I 2020-10-09 04:45:40,570] Trial 96 finished with value: 0.8006005589225786 and parameters: {'w1': -0.23990294694865738, 'w2': 0.047064387478754466, 'w3': -0.7716595497099632, 'w4': -0.03254841443765501}. Best is trial 77 with value: 0.8014569106242455.\n",
      "[I 2020-10-09 04:47:33,354] Trial 97 finished with value: 0.8009920096759835 and parameters: {'w1': -0.36616265509842716, 'w2': -0.23407278711665294, 'w3': -0.7342750200713913, 'w4': 0.052769352710745475}. Best is trial 77 with value: 0.8014569106242455.\n",
      "[I 2020-10-09 04:49:25,746] Trial 98 finished with value: 0.7964800134170701 and parameters: {'w1': -0.11300785839373338, 'w2': -0.11150399424810536, 'w3': -0.8077625580698575, 'w4': 0.194610857589366}. Best is trial 77 with value: 0.8014569106242455.\n",
      "[I 2020-10-09 04:51:12,319] Trial 99 finished with value: 0.8011674460168731 and parameters: {'w1': -0.3090627663259727, 'w2': -0.30282111478798335, 'w3': -0.9444991340062163, 'w4': -0.026256223989114064}. Best is trial 77 with value: 0.8014569106242455.\n"
     ]
    }
   ],
   "source": [
    "# Extracting the best model parameters and best study score for the 2nd Voting Classifier\n",
    "best_study_score,best_study_params = train_roc_auc(X_train_red, y_train, voting_clf_2, objective_wrappper_Vt_2,\n",
    "                                                   cv_strat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best roc_auc_score for the study is:  0.8014569106242455\n"
     ]
    }
   ],
   "source": [
    "print('The best roc_auc_score for the study is: ',best_study_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The best study parameters for the classifier are: ', {'w1': -0.01892659811471946, 'w2': -0.12205104743904709, 'w3': -0.4097477051900742, 'w4': -0.007396756446858069})\n"
     ]
    }
   ],
   "source": [
    "print(('The best study parameters for the classifier are: ',best_study_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining the best tuned voting clasiifier model by setting best study parameters.\n",
    "voting_clf_2 = voting_clf_2.set_params(weights=[best_study_params['w1'],best_study_params['w2'],\n",
    "                                                 best_study_params['w3'],best_study_params['w4']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('logistic_Reg',\n",
       "                              LogisticRegression(C=0.12725888493400458,\n",
       "                                                 class_weight={0: 1.0, 1: 9.0},\n",
       "                                                 l1_ratio=0.9851193622801032,\n",
       "                                                 n_jobs=5, penalty='elasticnet',\n",
       "                                                 random_state=42,\n",
       "                                                 solver='saga')),\n",
       "                             ('Random_Forest',\n",
       "                              RandomForestClassifier(class_weight='balanced',\n",
       "                                                     max_depth=11,\n",
       "                                                     min_samples_leaf=0.000264150675671259,\n",
       "                                                     n_estimators=1560,\n",
       "                                                     n_jobs=5,\n",
       "                                                     rando...\n",
       "                                             max_depth=85, min_child_samples=16,\n",
       "                                             n_estimators=1083, n_jobs=5,\n",
       "                                             num_leaves=26, objective='binary',\n",
       "                                             random_state=42,\n",
       "                                             reg_alpha=6.964534534541776,\n",
       "                                             reg_lambda=5.143496762382144)),\n",
       "                             ('Linear_Dis',\n",
       "                              LinearDiscriminantAnalysis(shrinkage=0.0023665526949698365,\n",
       "                                                         solver='eigen'))],\n",
       "                 n_jobs=5, voting='soft',\n",
       "                 weights=[-0.01892659811471946, -0.12205104743904709,\n",
       "                          -0.4097477051900742, -0.007396756446858069])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the best Voting Classifier on the reduced feature training set\n",
    "voting_clf_2.fit(X_train_red, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The roc_auc_score for the reduced feature training set using the best Voting Classifier is  0.8327689992475545\n"
     ]
    }
   ],
   "source": [
    "# Calculating the reduced feature training set roc_auc score using the best study parameters\n",
    "cal_roc_auc(X_train_red, y_train, voting_clf_2, 'reduced feature', 'training', 'Voting Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The roc_auc_score for the reduced feature test set using the best Voting Classifier is  0.8175044371196755\n"
     ]
    }
   ],
   "source": [
    "# Calculating the reduced feature test roc_auc score using the best study parameters\n",
    "cal_roc_auc(X_test_red, y_test, voting_clf_2, 'reduced feature', 'test', 'Voting Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Voting_Red.joblib']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the best voting Classifier\n",
    "import joblib\n",
    "joblib.dump(voting_clf_2,'Voting_Red.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating R_R ratio for the tuned Voting Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the best SVM  Classifier model\n",
    "import joblib\n",
    "voting_clf_2 = joblib.load('Voting_Red.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the CV scores using sklearn's cross_val_score\n",
    "score_voting_best = cross_val_score(voting_clf_2, X_train_red, y_train, cv=cv_strat, n_jobs=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reward associated with the tuned Voting Classifier using roc_auc metric is:  0.8014569106242455\n"
     ]
    }
   ],
   "source": [
    "print('The reward associated with the tuned Voting Classifier using roc_auc metric is: ',np.mean(score_voting_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The risk associated with the tuned Voting Classifier using roc_auc metric is:  0.01694969376455111\n"
     ]
    }
   ],
   "source": [
    "print('The risk associated with the tuned Voting Classifier using roc_auc metric is: ',np.std(score_voting_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_R_Ratio_voting = np.mean(score_voting_best)/np.std(score_voting_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reward risk ratio for the tuned voting Classifier using roc_auc metric is:  47.28444783471113\n"
     ]
    }
   ],
   "source": [
    "print('The reward risk ratio for the tuned Voting Classifier using roc_auc metric is: ',R_R_Ratio_voting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The R_R Ratio for the tuned Voting classifier using roc_auc metric is 47.28444783471113"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations: \n",
    "### 1)  The test set roc_auc score of the tuned voting classifier is more than that of all component models (by a good margin ), but for that of Light  GBM and also exceeds that of untuned  default voting classifier (voting_clf)\n",
    "### 2) On the other hand, quite surprisingly the R_R ratio for the tuned voting classifier model is more than that of only Light GBM (among the component models) and is also beaten down by that of the default voting classifier.  \n",
    "### 3) Again after accounting for all the factors, the tuned Random forest classifier still reigns supreme. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model_14: Voting Classifier with Tuned weights without LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf_3 = VotingClassifier(estimators=[('logistic_Reg',lr),('Random_Forest',rf),('Light_Gbm',lgbm)],\n",
    "                                           voting='soft',n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the appropriate objective function for the best weights of Voting classifier classifier\n",
    "def objective_wrappper_Vt_3(X_tr, y_tr, cls=None, cv_strat=None):\n",
    "    '''\n",
    "    Optimizes voting classifier (cls) weights parameter on the given training set X_tr, y_tr\n",
    "      \n",
    "    '''\n",
    "    \n",
    "    def objective(trial):\n",
    "        \n",
    "        w1 = trial.suggest_uniform('w1',0,1)\n",
    "        w2 = trial.suggest_uniform('w2',0,1)\n",
    "        w3 = trial.suggest_uniform('w3',0,1)\n",
    "        \n",
    "        \n",
    "        params = {\n",
    "            'weights':[w1,w2,w3]                 \n",
    "            }\n",
    "        \n",
    "        cls.set_params(**params)#Initializing the model with the parameter\n",
    "               \n",
    "        return np.mean(cross_val_score(cls, X_tr, y_tr, cv=cv_strat, n_jobs=5, scoring='roc_auc'))\n",
    "    \n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the evaluation function for study's best parameters\n",
    "def train_roc_auc(X_tr, y_tr, cls, obj_func, cv_strat, n_trials=100):\n",
    "    ''' Computes the best hyper parameters of the classsifier and returns \n",
    "    Optuna's study's best score & clasifier parameters'''\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(obj_func(X_tr, y_tr, cls, cv_strat), n_trials)\n",
    "    best_score = study.best_value\n",
    "    best_params = study.best_params\n",
    "    return (best_score,best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-09 23:51:02,311] A new study created in memory with name: no-name-285ed665-90bf-48ff-a1ff-a9f29cb259b7\n",
      "[I 2020-10-09 23:52:20,979] Trial 0 finished with value: 0.8013708950876163 and parameters: {'w1': 0.09102328342103017, 'w2': 0.6334135383619343, 'w3': 0.7309523997590622}. Best is trial 0 with value: 0.8013708950876163.\n",
      "[I 2020-10-09 23:53:20,170] Trial 1 finished with value: 0.8008370564675362 and parameters: {'w1': 0.6229923080810127, 'w2': 0.7272435684711895, 'w3': 0.9696964393180374}. Best is trial 0 with value: 0.8013708950876163.\n",
      "[I 2020-10-09 23:54:19,902] Trial 2 finished with value: 0.8008762774862301 and parameters: {'w1': 0.3262331688940634, 'w2': 0.177787139751987, 'w3': 0.6931711334747859}. Best is trial 0 with value: 0.8013708950876163.\n",
      "[I 2020-10-09 23:55:18,761] Trial 3 finished with value: 0.8002959001262322 and parameters: {'w1': 0.41596117681920475, 'w2': 0.7675176376135828, 'w3': 0.30487589664687}. Best is trial 0 with value: 0.8013708950876163.\n",
      "[I 2020-10-09 23:56:18,329] Trial 4 finished with value: 0.8003296917466638 and parameters: {'w1': 0.2643218920359822, 'w2': 0.7752062600078985, 'w3': 0.16101150891859273}. Best is trial 0 with value: 0.8013708950876163.\n",
      "[I 2020-10-09 23:57:17,121] Trial 5 finished with value: 0.8005189978921624 and parameters: {'w1': 0.7572047637796816, 'w2': 0.8513833041176838, 'w3': 0.8804603388010089}. Best is trial 0 with value: 0.8013708950876163.\n",
      "[I 2020-10-09 23:58:16,781] Trial 6 finished with value: 0.8008071600964346 and parameters: {'w1': 0.27929978317653836, 'w2': 0.26293838055898133, 'w3': 0.45543458889553556}. Best is trial 0 with value: 0.8013708950876163.\n",
      "[I 2020-10-09 23:59:16,179] Trial 7 finished with value: 0.7980336142889615 and parameters: {'w1': 0.7508036767995523, 'w2': 0.4063857424608539, 'w3': 0.19070457909193317}. Best is trial 0 with value: 0.8013708950876163.\n",
      "[I 2020-10-10 00:00:16,076] Trial 8 finished with value: 0.8013332781509069 and parameters: {'w1': 0.2646108063064565, 'w2': 0.7380315983870166, 'w3': 0.899308960279448}. Best is trial 0 with value: 0.8013708950876163.\n",
      "[I 2020-10-10 00:01:17,750] Trial 9 finished with value: 0.8007193794093806 and parameters: {'w1': 0.22835607469668529, 'w2': 0.8905086999039272, 'w3': 0.29159416796666193}. Best is trial 0 with value: 0.8013708950876163.\n",
      "[I 2020-10-10 00:02:16,806] Trial 10 finished with value: 0.8013782452095117 and parameters: {'w1': 0.008080938485980543, 'w2': 0.5169521492159346, 'w3': 0.6737312271269325}. Best is trial 10 with value: 0.8013782452095117.\n",
      "[I 2020-10-10 00:03:16,631] Trial 11 finished with value: 0.8013600893576317 and parameters: {'w1': 0.0010911511206761473, 'w2': 0.5304677972360207, 'w3': 0.6710471755470018}. Best is trial 10 with value: 0.8013782452095117.\n",
      "[I 2020-10-10 00:04:17,402] Trial 12 finished with value: 0.801380341393293 and parameters: {'w1': 0.01903684945022914, 'w2': 0.525209440612608, 'w3': 0.6810806314473288}. Best is trial 12 with value: 0.801380341393293.\n",
      "[I 2020-10-10 00:05:17,076] Trial 13 finished with value: 0.7988770958976612 and parameters: {'w1': 0.9649421178230605, 'w2': 0.41908316297971976, 'w3': 0.5318211811089176}. Best is trial 12 with value: 0.801380341393293.\n",
      "[I 2020-10-10 00:06:16,447] Trial 14 finished with value: 0.8012827830470888 and parameters: {'w1': 0.002949381698403364, 'w2': 0.5363461870923207, 'w3': 0.5563698480271048}. Best is trial 12 with value: 0.801380341393293.\n",
      "[I 2020-10-10 00:07:15,626] Trial 15 finished with value: 0.8014980764506412 and parameters: {'w1': 0.0915573165916524, 'w2': 0.3098690439872105, 'w3': 0.8102866566597007}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:08:14,542] Trial 16 finished with value: 0.8012722760796672 and parameters: {'w1': 0.12782892754344705, 'w2': 0.05947031577894696, 'w3': 0.8165150098905085}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:09:13,984] Trial 17 finished with value: 0.8014627175104932 and parameters: {'w1': 0.14095383039527737, 'w2': 0.30268960368572895, 'w3': 0.9925427882888923}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:10:15,454] Trial 18 finished with value: 0.8007589892615682 and parameters: {'w1': 0.4963391889615781, 'w2': 0.23932414450472544, 'w3': 0.9714715167524954}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:11:15,310] Trial 19 finished with value: 0.8013012609927825 and parameters: {'w1': 0.11911681143743985, 'w2': 0.06655510154211103, 'w3': 0.9932614067847794}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:12:15,442] Trial 20 finished with value: 0.8014485647023093 and parameters: {'w1': 0.15721150646938364, 'w2': 0.3009529168941324, 'w3': 0.8192343465127965}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:13:15,161] Trial 21 finished with value: 0.8014468218878561 and parameters: {'w1': 0.15899543531907848, 'w2': 0.29183498824715187, 'w3': 0.8186110664196414}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:14:14,497] Trial 22 finished with value: 0.801032259700091 and parameters: {'w1': 0.38089372349527745, 'w2': 0.3684785829808511, 'w3': 0.8003211631451895}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:15:14,249] Trial 23 finished with value: 0.8013693725005424 and parameters: {'w1': 0.18351898925996535, 'w2': 0.1967117959685843, 'w3': 0.8999214206064299}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:16:18,328] Trial 24 finished with value: 0.801388323093794 and parameters: {'w1': 0.06940163779823193, 'w2': 0.12926783841763925, 'w3': 0.9934504577851105}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:17:26,017] Trial 25 finished with value: 0.8014184337901151 and parameters: {'w1': 0.1882958093976961, 'w2': 0.32824790286857863, 'w3': 0.77906385862872}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:18:32,831] Trial 26 finished with value: 0.8011749602361139 and parameters: {'w1': 0.37540311183156494, 'w2': 0.4482773742537649, 'w3': 0.9116044601073371}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:19:39,849] Trial 27 finished with value: 0.80004714521832 and parameters: {'w1': 0.48794453634767143, 'w2': 0.13061414866501403, 'w3': 0.6071108168907684}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:20:47,043] Trial 28 finished with value: 0.7977987975523744 and parameters: {'w1': 0.05626971875267239, 'w2': 0.0023180190199555417, 'w3': 0.03237822096772952}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:21:48,691] Trial 29 finished with value: 0.8014200361758854 and parameters: {'w1': 0.09489532547230503, 'w2': 0.6016230397712512, 'w3': 0.7720252235590708}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:22:48,293] Trial 30 finished with value: 0.8007482063348444 and parameters: {'w1': 0.32252657495710063, 'w2': 0.3466967964354092, 'w3': 0.4747727041490981}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:23:47,339] Trial 31 finished with value: 0.8014330185201043 and parameters: {'w1': 0.16982340942457666, 'w2': 0.28024396557086506, 'w3': 0.8462935715665383}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:24:47,950] Trial 32 finished with value: 0.8014262794754128 and parameters: {'w1': 0.18151513528380983, 'w2': 0.30966644603655596, 'w3': 0.760000816088303}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:25:47,808] Trial 33 finished with value: 0.8014312732912081 and parameters: {'w1': 0.12593363636214722, 'w2': 0.2294767246285191, 'w3': 0.9500604848988496}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:26:47,883] Trial 34 finished with value: 0.8012801418421436 and parameters: {'w1': 0.22711192122603807, 'w2': 0.442631425073616, 'w3': 0.6127834641399956}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:27:50,734] Trial 35 finished with value: 0.8000063215456221 and parameters: {'w1': 0.5842868022310894, 'w2': 0.14800062432263558, 'w3': 0.7220486306796812}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:28:50,121] Trial 36 finished with value: 0.8014776123570311 and parameters: {'w1': 0.06638767329507028, 'w2': 0.3739505529377837, 'w3': 0.849269641285118}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:29:49,477] Trial 37 finished with value: 0.8014682207707031 and parameters: {'w1': 0.05952912653003378, 'w2': 0.3771634938412892, 'w3': 0.8625403250642205}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:30:49,372] Trial 38 finished with value: 0.8014376912719543 and parameters: {'w1': 0.045246162068756306, 'w2': 0.6047681351889346, 'w3': 0.9464077673521385}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:31:49,112] Trial 39 finished with value: 0.8014804622274975 and parameters: {'w1': 0.07284910612870617, 'w2': 0.3798714868650463, 'w3': 0.8640302562639397}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:32:48,362] Trial 40 finished with value: 0.8014864437084913 and parameters: {'w1': 0.07426137777797051, 'w2': 0.38178522344492605, 'w3': 0.8601120482119955}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:33:51,654] Trial 41 finished with value: 0.8014803486262598 and parameters: {'w1': 0.07529169366215699, 'w2': 0.39659410431093256, 'w3': 0.8640244514366584}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:34:59,367] Trial 42 finished with value: 0.8014675618800677 and parameters: {'w1': 0.09066065436635753, 'w2': 0.45591903140090595, 'w3': 0.8745243881942671}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:36:02,857] Trial 43 finished with value: 0.8013082938670448 and parameters: {'w1': 0.2531423515975751, 'w2': 0.4744523817642545, 'w3': 0.7231638063696375}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:37:03,510] Trial 44 finished with value: 0.8014220608775731 and parameters: {'w1': 0.008637990418925837, 'w2': 0.39817530519233235, 'w3': 0.9301657828346597}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:38:04,438] Trial 45 finished with value: 0.800781859923742 and parameters: {'w1': 0.3122531548601344, 'w2': 0.989247877855389, 'w3': 0.4075390757744768}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:39:05,073] Trial 46 finished with value: 0.7990747257674802 and parameters: {'w1': 0.9744642603499303, 'w2': 0.367422912193367, 'w3': 0.6392467249726752}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:40:03,858] Trial 47 finished with value: 0.8014050662730643 and parameters: {'w1': 0.22155185663883506, 'w2': 0.585962459604837, 'w3': 0.856052941874128}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:41:03,129] Trial 48 finished with value: 0.7999147698116437 and parameters: {'w1': 0.8137783457326315, 'w2': 0.49362607344409315, 'w3': 0.7441105340384624}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:42:02,467] Trial 49 finished with value: 0.8014188619301976 and parameters: {'w1': 0.001389261840983147, 'w2': 0.24267288165841086, 'w3': 0.9019612851466395}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:43:01,729] Trial 50 finished with value: 0.8013588711148246 and parameters: {'w1': 0.09554760741669666, 'w2': 0.6668851660527283, 'w3': 0.714028722060098}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:44:00,986] Trial 51 finished with value: 0.8014359819745135 and parameters: {'w1': 0.04398987068779918, 'w2': 0.393134970588508, 'w3': 0.8564381552017393}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:45:01,451] Trial 52 finished with value: 0.8014396314152371 and parameters: {'w1': 0.04077356581269251, 'w2': 0.41167206237339915, 'w3': 0.8383168120111464}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:46:08,582] Trial 53 finished with value: 0.8014904521436523 and parameters: {'w1': 0.08177163412382064, 'w2': 0.36408713220068417, 'w3': 0.7852264224996368}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:47:15,111] Trial 54 finished with value: 0.8014951584298092 and parameters: {'w1': 0.10591088496340112, 'w2': 0.3325162398925979, 'w3': 0.7936249811099603}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:48:22,345] Trial 55 finished with value: 0.8014473418469665 and parameters: {'w1': 0.11406371633789489, 'w2': 0.2155271307308279, 'w3': 0.7864637323508044}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:49:28,959] Trial 56 finished with value: 0.8013065683260321 and parameters: {'w1': 0.20979367342541574, 'w2': 0.2637463875540184, 'w3': 0.6795887377918866}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:50:36,008] Trial 57 finished with value: 0.8012536185458743 and parameters: {'w1': 0.2776394769001008, 'w2': 0.3210435948486361, 'w3': 0.8099958825845323}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:51:43,478] Trial 58 finished with value: 0.801444527873367 and parameters: {'w1': 0.01630342502178285, 'w2': 0.33891141676333164, 'w3': 0.9579884495308993}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:52:50,572] Trial 59 finished with value: 0.8014636337627763 and parameters: {'w1': 0.1466752705108404, 'w2': 0.5508572475572162, 'w3': 0.9003701492063976}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:53:57,459] Trial 60 finished with value: 0.8014510224421432 and parameters: {'w1': 0.09216828023718601, 'w2': 0.1781585182342284, 'w3': 0.6377373491968619}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:55:05,279] Trial 61 finished with value: 0.8014630888714903 and parameters: {'w1': 0.0861874151354376, 'w2': 0.427842709428066, 'w3': 0.7537779432740949}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:56:11,301] Trial 62 finished with value: 0.8014889809180878 and parameters: {'w1': 0.14473931543162744, 'w2': 0.35892030202397024, 'w3': 0.7980976745937057}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:57:18,087] Trial 63 finished with value: 0.8014921302693458 and parameters: {'w1': 0.13413075751187875, 'w2': 0.3498143679445513, 'w3': 0.7879192271445754}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:58:25,924] Trial 64 finished with value: 0.8014602346567223 and parameters: {'w1': 0.1389882064694511, 'w2': 0.2773426238469866, 'w3': 0.8011072426009452}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 00:59:32,815] Trial 65 finished with value: 0.8014095477020119 and parameters: {'w1': 0.1980567266482342, 'w2': 0.33943219832660315, 'w3': 0.7731142364185479}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 01:00:39,638] Trial 66 finished with value: 0.8014295690735924 and parameters: {'w1': 0.12258396477338589, 'w2': 0.49746718567116743, 'w3': 0.6968573974687253}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 01:01:46,662] Trial 67 finished with value: 0.8014471594290178 and parameters: {'w1': 0.03493960463185192, 'w2': 0.35262863401659755, 'w3': 0.8166160359325255}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 01:02:52,580] Trial 68 finished with value: 0.8010921863631717 and parameters: {'w1': 0.2504469557693002, 'w2': 0.2549850291803795, 'w3': 0.564450066142166}. Best is trial 15 with value: 0.8014980764506412.\n",
      "[I 2020-10-10 01:03:51,318] Trial 69 finished with value: 0.8014985302584225 and parameters: {'w1': 0.16295216012906855, 'w2': 0.4658787199076757, 'w3': 0.9256837614054116}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:04:50,590] Trial 70 finished with value: 0.8014893998588712 and parameters: {'w1': 0.17218222771507985, 'w2': 0.45804178902797876, 'w3': 0.9240928500093392}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:05:50,033] Trial 71 finished with value: 0.8014809826711922 and parameters: {'w1': 0.1588176135038808, 'w2': 0.46952969046968834, 'w3': 0.9984608097242702}. Best is trial 69 with value: 0.8014985302584225.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-10 01:06:49,978] Trial 72 finished with value: 0.8014637107835071 and parameters: {'w1': 0.18416705829383978, 'w2': 0.4184385947894099, 'w3': 0.9304569036554005}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:07:50,670] Trial 73 finished with value: 0.8014508560860051 and parameters: {'w1': 0.11353520623179661, 'w2': 0.5612279735176083, 'w3': 0.884841517590857}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:08:50,636] Trial 74 finished with value: 0.801461029882678 and parameters: {'w1': 0.1528259996761602, 'w2': 0.302368982579299, 'w3': 0.9737016696242646}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:09:51,430] Trial 75 finished with value: 0.8014156042911722 and parameters: {'w1': 0.21213033679478005, 'w2': 0.5088593536197344, 'w3': 0.8275012677018809}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:10:51,857] Trial 76 finished with value: 0.8014157752252569 and parameters: {'w1': 0.23679094398107914, 'w2': 0.4455677663230211, 'w3': 0.9177342138058387}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:11:52,604] Trial 77 finished with value: 0.8011788866398966 and parameters: {'w1': 0.2963634899746842, 'w2': 0.3263221786423607, 'w3': 0.7514066160194003}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:12:53,048] Trial 78 finished with value: 0.8011423548559297 and parameters: {'w1': 0.34551625772597155, 'w2': 0.28831441677031727, 'w3': 0.8813361805743779}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:13:53,156] Trial 79 finished with value: 0.8014708781066368 and parameters: {'w1': 0.17592681740171584, 'w2': 0.42955523095703263, 'w3': 0.7824164112481837}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:14:53,360] Trial 80 finished with value: 0.8014959443872881 and parameters: {'w1': 0.1282562344540084, 'w2': 0.35004718512218835, 'w3': 0.6996958597559058}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:15:52,643] Trial 81 finished with value: 0.8014895264411308 and parameters: {'w1': 0.11512971522254013, 'w2': 0.35228186906403613, 'w3': 0.7117840220480585}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:16:54,856] Trial 82 finished with value: 0.8014901063811763 and parameters: {'w1': 0.11170122751757908, 'w2': 0.36222065480526877, 'w3': 0.6574471874816312}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:17:54,623] Trial 83 finished with value: 0.8014981874902629 and parameters: {'w1': 0.11237057835367113, 'w2': 0.3158829982004639, 'w3': 0.6544811620856824}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:18:55,403] Trial 84 finished with value: 0.801456205451926 and parameters: {'w1': 0.1099978366750035, 'w2': 0.21636466034292942, 'w3': 0.6605204706655522}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:19:55,406] Trial 85 finished with value: 0.8014382491096737 and parameters: {'w1': 0.024414489374687945, 'w2': 0.31346927146428666, 'w3': 0.611023736811146}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:20:54,558] Trial 86 finished with value: 0.8014651601922737 and parameters: {'w1': 0.11814402851454622, 'w2': 0.3522192756601069, 'w3': 0.5824887305508095}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:21:55,032] Trial 87 finished with value: 0.8014617327443212 and parameters: {'w1': 0.053569633604729196, 'w2': 0.2956941976422198, 'w3': 0.520604198623656}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:22:56,473] Trial 88 finished with value: 0.8005753387042327 and parameters: {'w1': 0.46235672081066176, 'w2': 0.27079593346925523, 'w3': 0.7098308476274683}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:23:55,609] Trial 89 finished with value: 0.80020910004281 and parameters: {'w1': 0.6095108316258925, 'w2': 0.4074739701880748, 'w3': 0.6611287039922692}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:25:00,082] Trial 90 finished with value: 0.8014054061421971 and parameters: {'w1': 0.0029992754125919147, 'w2': 0.327211262061775, 'w3': 0.6388384237216553}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:26:01,135] Trial 91 finished with value: 0.8014646337080631 and parameters: {'w1': 0.16495966930595235, 'w2': 0.38108306320900065, 'w3': 0.7326837813414477}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:27:01,249] Trial 92 finished with value: 0.8013777495162314 and parameters: {'w1': 0.19766224998009746, 'w2': 0.4811230232950006, 'w3': 0.6961383815101106}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:28:02,062] Trial 93 finished with value: 0.8014624875473471 and parameters: {'w1': 0.1381071025762147, 'w2': 0.4598901692058284, 'w3': 0.7382978283892635}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:29:01,657] Trial 94 finished with value: 0.8014827700711156 and parameters: {'w1': 0.10191860293639748, 'w2': 0.3643445499052228, 'w3': 0.666110144705909}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:30:01,048] Trial 95 finished with value: 0.8014754919593032 and parameters: {'w1': 0.07276141598306915, 'w2': 0.39417353030574875, 'w3': 0.7644419235629987}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:31:00,218] Trial 96 finished with value: 0.8013918598851542 and parameters: {'w1': 0.17118271756488374, 'w2': 0.24335972866192274, 'w3': 0.6998380122829054}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:32:00,430] Trial 97 finished with value: 0.801173126788151 and parameters: {'w1': 0.1333249252897588, 'w2': 0.5297550175361208, 'w3': 0.38423620825796595}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:33:01,364] Trial 98 finished with value: 0.8014689933144592 and parameters: {'w1': 0.059562302435045775, 'w2': 0.3461274950046318, 'w3': 0.5903155616929183}. Best is trial 69 with value: 0.8014985302584225.\n",
      "[I 2020-10-10 01:34:01,455] Trial 99 finished with value: 0.8014720775269619 and parameters: {'w1': 0.09358507447451726, 'w2': 0.42933647534304387, 'w3': 0.8405159055972494}. Best is trial 69 with value: 0.8014985302584225.\n"
     ]
    }
   ],
   "source": [
    "# Extracting the best model parameters and best study score\n",
    "best_study_score,best_study_params = train_roc_auc(X_train_red, y_train, voting_clf_3, objective_wrappper_Vt_3,\n",
    "                                                   cv_strat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best roc_auc_score for the study is:  0.8014985302584225\n"
     ]
    }
   ],
   "source": [
    "print('The best roc_auc_score for the study is: ',best_study_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The best study parameters for the classifier are: ', {'w1': 0.16295216012906855, 'w2': 0.4658787199076757, 'w3': 0.9256837614054116})\n"
     ]
    }
   ],
   "source": [
    "print(('The best study parameters for the classifier are: ',best_study_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining the best reduced feature LR model by setting best study parameters.\n",
    "voting_clf_3 = voting_clf_3.set_params(weights=[best_study_params['w1'],best_study_params['w2'],\n",
    "                                                 best_study_params['w3']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('logistic_Reg',\n",
       "                              LogisticRegression(C=0.12725888493400458,\n",
       "                                                 class_weight={0: 1.0, 1: 9.0},\n",
       "                                                 l1_ratio=0.9851193622801032,\n",
       "                                                 n_jobs=5, penalty='elasticnet',\n",
       "                                                 random_state=42,\n",
       "                                                 solver='saga')),\n",
       "                             ('Random_Forest',\n",
       "                              RandomForestClassifier(class_weight='balanced',\n",
       "                                                     max_depth=11,\n",
       "                                                     min_samples_leaf=0.000264150675671259,\n",
       "                                                     n_estimators=1560,\n",
       "                                                     n_jobs=5,\n",
       "                                                     rando...\n",
       "                              LGBMClassifier(class_weight={0: 1.0, 1: 11},\n",
       "                                             colsample_bytree=0.6688983257726496,\n",
       "                                             learning_rate=0.0030081514412958507,\n",
       "                                             max_depth=85, min_child_samples=16,\n",
       "                                             n_estimators=1083, n_jobs=5,\n",
       "                                             num_leaves=26, objective='binary',\n",
       "                                             random_state=42,\n",
       "                                             reg_alpha=6.964534534541776,\n",
       "                                             reg_lambda=5.143496762382144))],\n",
       "                 n_jobs=5, voting='soft',\n",
       "                 weights=[0.16295216012906855, 0.4658787199076757,\n",
       "                          0.9256837614054116])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the best Voting Classifier on the full feature training set\n",
    "voting_clf_3.fit(X_train_red, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the best voting Classifier without lda\n",
    "import joblib\n",
    "voting_clf_3 = joblib.load('Voting_Red_without_lda.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The roc_auc_score for the reduced feature training set using the tuned Voting Classifier without lda is  0.8340876676343492\n"
     ]
    }
   ],
   "source": [
    "# Calculating the reduced feature training set roc_auc score using the best study parameters\n",
    "cal_roc_auc(X_train_red, y_train, voting_clf_3, 'reduced feature', 'training', 'tuned Voting Classifier without lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The roc_auc_score for the reduced feature test set using the tuned Voting Classifier without lda is  0.8166479698334828\n"
     ]
    }
   ],
   "source": [
    "# Calculating the reduced feature test roc_auc score using the best study parameters\n",
    "cal_roc_auc(X_test_red, y_test, voting_clf_3, 'reduced feature', 'test', 'tuned Voting Classifier without lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Voting_Red_without_lda.joblib']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the best voting Classifier without lda\n",
    "import joblib\n",
    "joblib.dump(voting_clf_3,'Voting_Red_without_lda.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating R_R ratio for the tuned Voting Classifier without  LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('logistic_Reg',\n",
       "                              LogisticRegression(C=0.12725888493400458,\n",
       "                                                 class_weight={0: 1.0, 1: 9.0},\n",
       "                                                 l1_ratio=0.9851193622801032,\n",
       "                                                 n_jobs=5, penalty='elasticnet',\n",
       "                                                 random_state=42,\n",
       "                                                 solver='saga')),\n",
       "                             ('Random_Forest',\n",
       "                              RandomForestClassifier(class_weight='balanced',\n",
       "                                                     max_depth=11,\n",
       "                                                     min_samples_leaf=0.000264150675671259,\n",
       "                                                     n_estimators=1560,\n",
       "                                                     n_jobs=5,\n",
       "                                                     rando...\n",
       "                              LGBMClassifier(class_weight={0: 1.0, 1: 11},\n",
       "                                             colsample_bytree=0.6688983257726496,\n",
       "                                             learning_rate=0.0030081514412958507,\n",
       "                                             max_depth=85, min_child_samples=16,\n",
       "                                             n_estimators=1083, n_jobs=5,\n",
       "                                             num_leaves=26, objective='binary',\n",
       "                                             random_state=42,\n",
       "                                             reg_alpha=6.964534534541776,\n",
       "                                             reg_lambda=5.143496762382144))],\n",
       "                 n_jobs=5, voting='soft',\n",
       "                 weights=[0.16295216012906855, 0.4658787199076757,\n",
       "                          0.9256837614054116])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the CV scores using sklearn's cross_val_score\n",
    "score_voting_3 = cross_val_score(voting_clf_3, X_train_red, y_train, cv=cv_strat, n_jobs=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reward associated with the tuned Voting Classifier without lda using roc_auc metric is:  0.8014985302584225\n"
     ]
    }
   ],
   "source": [
    "print('The reward associated with the tuned Voting Classifier without lda using roc_auc metric is: ',np.mean(score_voting_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The risk associated with the tuned Voting Classifier using roc_auc metric is:  0.0166290787448371\n"
     ]
    }
   ],
   "source": [
    "print('The risk associated with the tuned Voting Classifier using roc_auc metric is: ',np.std(score_voting_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_R_Ratio_voting_without_lda = np.mean(score_voting_3)/np.std(score_voting_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reward risk ratio for the tuned Voting Classifier without lda using roc_auc metric is:  48.19861295727324\n"
     ]
    }
   ],
   "source": [
    "print('The reward risk ratio for the tuned Voting Classifier without lda using roc_auc metric is: ',R_R_Ratio_voting_without_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The R_R Ratio for the tuned Voting classifier without lda using roc_auc metric is 48.19861295727324"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations: \n",
    "### 1) The voting classifier with lda outperformed the one without lda, in terms of test set roc_auc score, which was expected as the voting classifier performs well when the constituent models are many and well diversified.\n",
    "### 2)  The test set roc_auc score of the tuned voting classifier without lda is more than that of all component models (by a good margin ), but for that of Light  GBM and also exceeds that of untuned  default voting classifier (voting_clf)\n",
    "### 3) Again, the R-R ratio for the tuned voting classifier without lda is more than that of only Light GBM (among the component models) & tuned voting classifier with lda. But is beaten down by that of the default voting classifier. \n",
    "### 4) Taking everything into consideration( such as computational cost), the tuned Random forest classifier has beaten all the voting classifiers & is clearly the winner till here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best R_R Ratio for the voting classifier family using roc_auc metric is:  49.271728792879195 ,corresponding to default Voting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Thus keeping everything into account (including the computational costs), for this dataset , the best Voting Classifier is the tuned Voting Classifier with lda._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
